{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:19:59.170054100Z",
     "start_time": "2024-06-07T11:19:58.977474500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "view_log_train = pd.read_csv('../data/view_log.csv')\n",
    "article_info = pd.read_csv('../data/article_info.csv')\n",
    "submission = pd.read_csv('../submission/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "       userID     articleID userRegion userCountry\n0   USER_0000  ARTICLE_0661         NY          US\n1   USER_0000  ARTICLE_2316         NY          US\n2   USER_0000  ARTICLE_1345         NY          US\n3   USER_0000  ARTICLE_1089         NY          US\n4   USER_0000  ARTICLE_1484         NY          US\n..        ...           ...        ...         ...\n95  USER_0005  ARTICLE_0564         MG          BR\n96  USER_0005  ARTICLE_0931         MG          BR\n97  USER_0005  ARTICLE_2223         MG          BR\n98  USER_0005  ARTICLE_1577         MG          BR\n99  USER_0005  ARTICLE_3003         MG          BR\n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID</th>\n      <th>articleID</th>\n      <th>userRegion</th>\n      <th>userCountry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>USER_0000</td>\n      <td>ARTICLE_0661</td>\n      <td>NY</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>USER_0000</td>\n      <td>ARTICLE_2316</td>\n      <td>NY</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USER_0000</td>\n      <td>ARTICLE_1345</td>\n      <td>NY</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>USER_0000</td>\n      <td>ARTICLE_1089</td>\n      <td>NY</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>USER_0000</td>\n      <td>ARTICLE_1484</td>\n      <td>NY</td>\n      <td>US</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>USER_0005</td>\n      <td>ARTICLE_0564</td>\n      <td>MG</td>\n      <td>BR</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>USER_0005</td>\n      <td>ARTICLE_0931</td>\n      <td>MG</td>\n      <td>BR</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>USER_0005</td>\n      <td>ARTICLE_2223</td>\n      <td>MG</td>\n      <td>BR</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>USER_0005</td>\n      <td>ARTICLE_1577</td>\n      <td>MG</td>\n      <td>BR</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>USER_0005</td>\n      <td>ARTICLE_3003</td>\n      <td>MG</td>\n      <td>BR</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_log_train.head(100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:20:01.604086300Z",
     "start_time": "2024-06-07T11:20:01.570176200Z"
    }
   },
   "id": "753224c31e586387"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "view_log_train.drop(['userRegion','userCountry'],axis =1 , inplace=True)\n",
    "df = view_log_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:20:04.094275Z",
     "start_time": "2024-06-07T11:20:04.077320200Z"
    }
   },
   "id": "aa2407e8612d106"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# 사용자 및 기사 인덱스 생성\n",
    "df['user_id'] = df['userID'].astype('category').cat.codes\n",
    "df['article_id'] = df['articleID'].astype('category').cat.codes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:20:04.811953900Z",
     "start_time": "2024-06-07T11:20:04.785382600Z"
    }
   },
   "id": "a65555e38111bc1"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# 학습 및 테스트 데이터셋 분할\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:20:05.049482300Z",
     "start_time": "2024-06-07T11:20:05.025713400Z"
    }
   },
   "id": "f8e49ab228ce5bf6"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# PyTorch 데이터셋 생성\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.users = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
    "        self.articles = torch.tensor(df['article_id'].values, dtype=torch.long)\n",
    "        self.labels = torch.tensor([1] * len(df), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.articles[idx], self.labels[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:20:05.280674800Z",
     "start_time": "2024-06-07T11:20:05.260727700Z"
    }
   },
   "id": "837bf7eeaa56e96d"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "train_dataset = InteractionDataset(train)\n",
    "test_dataset = InteractionDataset(test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:20:17.174184100Z",
     "start_time": "2024-06-07T11:20:17.152242900Z"
    }
   },
   "id": "cd1291c27947ff12"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# BERT4Rec 모델 정의\n",
    "class BERT4Rec(nn.Module):\n",
    "    def __init__(self, num_users, num_articles, embedding_size, num_layers, num_heads, dropout_rate, max_seq_length):\n",
    "        super(BERT4Rec, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.article_embedding = nn.Embedding(num_articles, embedding_size)\n",
    "        self.positional_embedding = nn.Embedding(max_seq_length, embedding_size)\n",
    "        self.transformer = nn.Transformer(d_model=embedding_size, nhead=num_heads, num_encoder_layers=num_layers, num_decoder_layers=num_layers, dropout=dropout_rate)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(embedding_size, 1)\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def forward(self, user_ids, article_ids):\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        article_emb = self.article_embedding(article_ids)\n",
    "        position_ids = torch.arange(article_emb.size(1), device=article_emb.device).unsqueeze(0).expand_as(article_ids)\n",
    "        position_emb = self.positional_embedding(position_ids)\n",
    "        x = user_emb + article_emb + position_emb\n",
    "        x = self.dropout(x)\n",
    "        x = x.permute(1, 0, 2)  # Transformer expects input shape (seq_length, batch_size, embedding_size)\n",
    "        transformer_output = self.transformer(x, x)\n",
    "        transformer_output = transformer_output.permute(1, 0, 2)  # Convert back to (batch_size, seq_length, embedding_size)\n",
    "        x = transformer_output.mean(dim=1)\n",
    "        x = self.fc(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "num_users = df['user_id'].nunique()\n",
    "num_articles = df['article_id'].nunique()\n",
    "embedding_size = 50\n",
    "num_layers = 2\n",
    "num_heads = 2\n",
    "dropout_rate = 0.1\n",
    "max_seq_length = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:24:20.378744Z",
     "start_time": "2024-06-07T11:24:20.364780400Z"
    }
   },
   "id": "32f7b9befc38df53"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SJ\\anaconda3\\envs\\study\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = BERT4Rec(num_users, num_articles, embedding_size, num_layers, num_heads, dropout_rate, max_seq_length)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:34:44.875082900Z",
     "start_time": "2024-06-07T11:34:44.844167700Z"
    }
   },
   "id": "4e5421261c40ddcd"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0001, Validation Loss: 0.0000\n",
      "Epoch 2/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 3/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 4/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 5/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 6/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 7/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 8/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 9/10, Loss: 0.0000, Validation Loss: 0.0000\n",
      "Epoch 10/10, Loss: 0.0000, Validation Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "def train_model(model, criterion, optimizer, num_epochs=5):\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for users, articles, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(users.unsqueeze(1), articles.unsqueeze(1))\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * users.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for users, articles, labels in val_loader:\n",
    "                outputs = model(users.unsqueeze(1), articles.unsqueeze(1))\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                val_loss += loss.item() * users.size(0)\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "train_model(model, criterion, optimizer, num_epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:40:48.410237800Z",
     "start_time": "2024-06-07T11:38:31.434590600Z"
    }
   },
   "id": "7665a78f49f6fc19"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 기사: ['ARTICLE_3007', 'ARTICLE_0985', 'ARTICLE_1006', 'ARTICLE_1005', 'ARTICLE_1004']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 특정 사용자에 대한 추천 생성 함수\n",
    "def recommend_articles(user_id, num_recommendations=5):\n",
    "    user_index = df[df['userID'] == user_id]['user_id'].iloc[0]\n",
    "    article_indices = torch.tensor([i for i in range(num_articles)], dtype=torch.long)\n",
    "\n",
    "    user_indices = torch.tensor([user_index] * num_articles, dtype=torch.long)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_indices.unsqueeze(1), article_indices.unsqueeze(1)).squeeze().numpy()\n",
    "    top_articles = predictions.argsort()[-num_recommendations:][::-1]\n",
    "\n",
    "    recommended_article_ids = df['articleID'].astype('category').cat.categories[top_articles].tolist()\n",
    "    return recommended_article_ids\n",
    "\n",
    "# 예시 사용자에 대한 추천\n",
    "recommended_articles = recommend_articles('USER_0001', 5)\n",
    "print(f\"추천 기사: {recommended_articles}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:40:53.044325Z",
     "start_time": "2024-06-07T11:40:52.975507300Z"
    }
   },
   "id": "238f3471bd805f4a"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# 모든 사용자에 대해 추천 생성\n",
    "recommendations = []\n",
    "unique_users = df['userID'].unique()\n",
    "\n",
    "for user in unique_users:\n",
    "    recommended_articles = recommend_articles(user, 5)\n",
    "    for article in recommended_articles:\n",
    "        recommendations.append([user, article])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:29:23.611885300Z",
     "start_time": "2024-06-07T11:28:01.142160Z"
    }
   },
   "id": "cb716808bee2c8a8"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userID     articleID\n",
      "0  USER_0000  ARTICLE_2202\n",
      "1  USER_0000  ARTICLE_0437\n",
      "2  USER_0000  ARTICLE_1746\n",
      "3  USER_0000  ARTICLE_2409\n",
      "4  USER_0000  ARTICLE_2837\n"
     ]
    }
   ],
   "source": [
    "# 추천 결과를 데이터프레임으로 변환\n",
    "top_recommendations = pd.DataFrame(recommendations, columns=['userID', 'articleID'])\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = pd.DataFrame(columns=['userID', 'articleID'])\n",
    "submission['userID'] = top_recommendations['userID']\n",
    "submission['articleID'] = top_recommendations['articleID']\n",
    "\n",
    "# 파일 저장\n",
    "submission.to_csv('../submission/SASRec3.csv', index=False)\n",
    "\n",
    "print(submission.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-07T11:29:31.110037700Z",
     "start_time": "2024-06-07T11:29:31.049051400Z"
    }
   },
   "id": "eeb5498b7d5dfd33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "542948cd27f07eb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
