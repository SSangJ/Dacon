{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:10.934558500Z",
     "start_time": "2024-04-03T12:33:10.915731600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    " import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import _target_encoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import pandas as pd\n",
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "\n",
    "import warnings\n",
    "\n",
    "# 경고 무시\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # 예시로 'NanumGothic'을 사용"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:11.144627800Z",
     "start_time": "2024-04-03T12:33:11.124554900Z"
    }
   },
   "id": "d3485897f6b2687a"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42) # Seed 고정"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:11.321420Z",
     "start_time": "2024-04-03T12:33:11.302154700Z"
    }
   },
   "id": "a5105ad2fc7053f2"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:11.559020900Z",
     "start_time": "2024-04-03T12:33:11.455716600Z"
    }
   },
   "id": "ac56d78661e6c8da"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "train = train.drop(['ID'], axis=1)\n",
    "test = test.drop(['ID'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:11.928842200Z",
     "start_time": "2024-04-03T12:33:11.900175400Z"
    }
   },
   "id": "9331e702e78a7adf"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "       Age Gender                Education_Status         Employment_Status  \\\n0       63      M                    Middle (7-8)                 Full-Time   \n1       37      M  Associates degree (Vocational)                 Full-Time   \n2       58      F                   High graduate                 Full-Time   \n3       44      M                   High graduate                 Full-Time   \n4       37      F                   High graduate                 Full-Time   \n...    ...    ...                             ...                       ...   \n19995   33      M                   High graduate  Children or Armed Forces   \n19996   20      F                         College                 Full-Time   \n19997   22      M                         College  Children or Armed Forces   \n19998   76      F                   High graduate               Not Working   \n19999   41      F                   High graduate  Children or Armed Forces   \n\n       Working_Week (Yearly)              Industry_Status  \\\n0                          4              Social Services   \n1                         52                Entertainment   \n2                         52  Manufacturing (Non-durable)   \n3                         52                       Retail   \n4                         52                       Retail   \n...                      ...                          ...   \n19995                     52      Manufacturing (Durable)   \n19996                     12                    Education   \n19997                     52               Transportation   \n19998                      0  Not in universe or children   \n19999                     52        Public Administration   \n\n                      Occupation_Status   Race    Hispanic_Origin  \\\n0                              Services  White          All other   \n1                              Services  White          All other   \n2      Admin Support (include Clerical)  Black          All other   \n3                 Technicians & Support  White          All other   \n4                                 Sales  White          All other   \n...                                 ...    ...                ...   \n19995                 Handlers/Cleaners  White          All other   \n19996  Admin Support (include Clerical)  White   Mexican-American   \n19997             Technicians & Support  White          All other   \n19998                           Unknown  White          All other   \n19999  Admin Support (include Clerical)  White          All other   \n\n      Martial_Status  ... Citizenship Birth_Country Birth_Country (Father)  \\\n0            Married  ...      Native            US                     US   \n1          Separated  ...      Native            US                     US   \n2            Married  ...      Native            US                     US   \n3           Divorced  ...      Native            US                     US   \n4           Divorced  ...      Native            US                     US   \n...              ...  ...         ...           ...                    ...   \n19995         Single  ...      Native            US                     US   \n19996         Single  ...      Native            US                 Mexico   \n19997         Single  ...      Native            US                     US   \n19998        Widowed  ...      Native            US               Scotland   \n19999      Separated  ...      Native            US                     US   \n\n      Birth_Country (Mother)                                   Tax_Status  \\\n0                         US                                     Nonfiler   \n1                         US                                       Single   \n2                         US  Married Filling Jointly both under 65 (MFJ)   \n3                         US                                       Single   \n4                         US                      Head of Household (HOH)   \n...                      ...                                          ...   \n19995                     US                                       Single   \n19996                 Mexico                                     Nonfiler   \n19997                     US                                       Single   \n19998                England                                       Single   \n19999                     US                      Head of Household (HOH)   \n\n      Gains Losses  Dividends  Income_Status  Income  \n0         0      0          0        Unknown     425  \n1         0      0          0   Under Median       0  \n2      3411      0          0   Under Median     860  \n3         0      0          0   Under Median     850  \n4         0      0          0        Unknown     570  \n...     ...    ...        ...            ...     ...  \n19995     0      0          0   Under Median    1300  \n19996     0      0          0   Under Median     850  \n19997     0      0          0        Unknown     999  \n19998     0      0          0   Under Median       0  \n19999     0      0          0   Under Median     671  \n\n[20000 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>Education_Status</th>\n      <th>Employment_Status</th>\n      <th>Working_Week (Yearly)</th>\n      <th>Industry_Status</th>\n      <th>Occupation_Status</th>\n      <th>Race</th>\n      <th>Hispanic_Origin</th>\n      <th>Martial_Status</th>\n      <th>...</th>\n      <th>Citizenship</th>\n      <th>Birth_Country</th>\n      <th>Birth_Country (Father)</th>\n      <th>Birth_Country (Mother)</th>\n      <th>Tax_Status</th>\n      <th>Gains</th>\n      <th>Losses</th>\n      <th>Dividends</th>\n      <th>Income_Status</th>\n      <th>Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>M</td>\n      <td>Middle (7-8)</td>\n      <td>Full-Time</td>\n      <td>4</td>\n      <td>Social Services</td>\n      <td>Services</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Married</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Nonfiler</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Unknown</td>\n      <td>425</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>M</td>\n      <td>Associates degree (Vocational)</td>\n      <td>Full-Time</td>\n      <td>52</td>\n      <td>Entertainment</td>\n      <td>Services</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Separated</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Single</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Under Median</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>58</td>\n      <td>F</td>\n      <td>High graduate</td>\n      <td>Full-Time</td>\n      <td>52</td>\n      <td>Manufacturing (Non-durable)</td>\n      <td>Admin Support (include Clerical)</td>\n      <td>Black</td>\n      <td>All other</td>\n      <td>Married</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Married Filling Jointly both under 65 (MFJ)</td>\n      <td>3411</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Under Median</td>\n      <td>860</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44</td>\n      <td>M</td>\n      <td>High graduate</td>\n      <td>Full-Time</td>\n      <td>52</td>\n      <td>Retail</td>\n      <td>Technicians &amp; Support</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Divorced</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Single</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Under Median</td>\n      <td>850</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>37</td>\n      <td>F</td>\n      <td>High graduate</td>\n      <td>Full-Time</td>\n      <td>52</td>\n      <td>Retail</td>\n      <td>Sales</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Divorced</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Head of Household (HOH)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Unknown</td>\n      <td>570</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>33</td>\n      <td>M</td>\n      <td>High graduate</td>\n      <td>Children or Armed Forces</td>\n      <td>52</td>\n      <td>Manufacturing (Durable)</td>\n      <td>Handlers/Cleaners</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Single</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Single</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Under Median</td>\n      <td>1300</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>20</td>\n      <td>F</td>\n      <td>College</td>\n      <td>Full-Time</td>\n      <td>12</td>\n      <td>Education</td>\n      <td>Admin Support (include Clerical)</td>\n      <td>White</td>\n      <td>Mexican-American</td>\n      <td>Single</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>Mexico</td>\n      <td>Mexico</td>\n      <td>Nonfiler</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Under Median</td>\n      <td>850</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>22</td>\n      <td>M</td>\n      <td>College</td>\n      <td>Children or Armed Forces</td>\n      <td>52</td>\n      <td>Transportation</td>\n      <td>Technicians &amp; Support</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Single</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Single</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Unknown</td>\n      <td>999</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>76</td>\n      <td>F</td>\n      <td>High graduate</td>\n      <td>Not Working</td>\n      <td>0</td>\n      <td>Not in universe or children</td>\n      <td>Unknown</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Widowed</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>Scotland</td>\n      <td>England</td>\n      <td>Single</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Under Median</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>41</td>\n      <td>F</td>\n      <td>High graduate</td>\n      <td>Children or Armed Forces</td>\n      <td>52</td>\n      <td>Public Administration</td>\n      <td>Admin Support (include Clerical)</td>\n      <td>White</td>\n      <td>All other</td>\n      <td>Separated</td>\n      <td>...</td>\n      <td>Native</td>\n      <td>US</td>\n      <td>US</td>\n      <td>US</td>\n      <td>Head of Household (HOH)</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Under Median</td>\n      <td>671</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:12.468137400Z",
     "start_time": "2024-04-03T12:33:12.403310900Z"
    }
   },
   "id": "4249b3f0275f17c4"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Age                     20000 non-null  int64 \n",
      " 1   Gender                  20000 non-null  object\n",
      " 2   Education_Status        20000 non-null  object\n",
      " 3   Employment_Status       20000 non-null  object\n",
      " 4   Working_Week (Yearly)   20000 non-null  int64 \n",
      " 5   Industry_Status         20000 non-null  object\n",
      " 6   Occupation_Status       20000 non-null  object\n",
      " 7   Race                    20000 non-null  object\n",
      " 8   Hispanic_Origin         20000 non-null  object\n",
      " 9   Martial_Status          20000 non-null  object\n",
      " 10  Household_Status        20000 non-null  object\n",
      " 11  Household_Summary       20000 non-null  object\n",
      " 12  Citizenship             20000 non-null  object\n",
      " 13  Birth_Country           20000 non-null  object\n",
      " 14  Birth_Country (Father)  20000 non-null  object\n",
      " 15  Birth_Country (Mother)  20000 non-null  object\n",
      " 16  Tax_Status              20000 non-null  object\n",
      " 17  Gains                   20000 non-null  int64 \n",
      " 18  Losses                  20000 non-null  int64 \n",
      " 19  Dividends               20000 non-null  int64 \n",
      " 20  Income_Status           20000 non-null  object\n",
      " 21  Income                  20000 non-null  int64 \n",
      "dtypes: int64(6), object(16)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:12.558894500Z",
     "start_time": "2024-04-03T12:33:12.448190900Z"
    }
   },
   "id": "1186b4769a9e640b"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "test['Household_Status'].fillna('Nonfamily householder', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:12.636688800Z",
     "start_time": "2024-04-03T12:33:12.511023300Z"
    }
   },
   "id": "7518e618a6b9e607"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# 원-핫 인코딩을 적용할 열 지정\n",
    "one_hot_cols = ['Gender']\n",
    "# one_hot_cols = ['Gender', 'Income_Status','Tax_Status','Citizenship','Industry_Status','Occupation_Status']\n",
    "# 원-핫 인코더 생성 및 train 데이터에 적용\n",
    "one_hot_encoder = OneHotEncoder(cols=one_hot_cols, use_cat_names=True)\n",
    "train_encoded = one_hot_encoder.fit_transform(train[one_hot_cols])\n",
    "\n",
    "# 동일한 원-핫 인코더를 test 데이터에 적용\n",
    "test_encoded = one_hot_encoder.transform(test[one_hot_cols])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:12.698521400Z",
     "start_time": "2024-04-03T12:33:12.626713900Z"
    }
   },
   "id": "3fea110a46583709"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# # 레이블 인코더 객체 생성\n",
    "# label_encoder = LabelEncoder()\n",
    "# \n",
    "# # one_hot_cols에 명시된 열을 제외한 카테고리형 변수를 인코딩 대상으로 설정\n",
    "# encoding_target = [col for col in train.columns if train[col].dtype == 'object' and col not in one_hot_cols]\n",
    "# \n",
    "# # 인코딩 대상 열에 대해 레이블 인코딩 적용\n",
    "# for col in encoding_target:\n",
    "#     # train과 test 데이터셋에서 해당 열의 모든 값을 문자열로 변환\n",
    "#     test_encoded[col] = train[col].astype(str)\n",
    "#     test_encoded[col] = test[col].astype(str)\n",
    "# \n",
    "#     # 레이블 인코더를 train 데이터에 적합시키고 변환\n",
    "#     label_encoder.fit(train[col])\n",
    "#     train_encoded[col] = label_encoder.transform(train[col])\n",
    "# \n",
    "#     # test 데이터에도 동일한 인코더를 적용\n",
    "#     test_encoded[col] = label_encoder.transform(test[col])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:13.039098100Z",
     "start_time": "2024-04-03T12:33:13.014165300Z"
    }
   },
   "id": "a3c7e9caea9635d"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "\n",
    "# 타겟 인코더 객체 생성\n",
    "target_encoder = TargetEncoder()\n",
    "\n",
    "# one_hot_cols에 명시된 열을 제외한 카테고리형 변수를 인코딩 대상으로 설정\n",
    "encoding_target = [col for col in train.columns if train[col].dtype == 'object' and col not in one_hot_cols]\n",
    "\n",
    "# 인코딩 대상 열에 대해 타겟 인코딩 적용\n",
    "for col in encoding_target:\n",
    "    # 타겟 인코더를 train 데이터의 해당 열과 타겟에 적합시키고 train 데이터 변환\n",
    "    train_encoded[col] = target_encoder.fit_transform(train[col], train['Income'])\n",
    "\n",
    "    # test 데이터에는 적합시킨 인코더를 이용해 변환만 적용\n",
    "    test_encoded[col] = target_encoder.transform(test[col])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:13.527012500Z",
     "start_time": "2024-04-03T12:33:13.230584900Z"
    }
   },
   "id": "6cbeef83afa25855"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "train_encoded = pd.concat([train_encoded, train[['Working_Week (Yearly)','Age','Gains','Losses','Income']]], axis=1)\n",
    "test_encoded = pd.concat([test_encoded, test[['Working_Week (Yearly)','Age','Gains','Losses']]], axis=1)\n",
    "\n",
    "train = train_encoded\n",
    "test = test_encoded"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:13.541972100Z",
     "start_time": "2024-04-03T12:33:13.528010600Z"
    }
   },
   "id": "4487a2e1304a8a28"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "train = train.drop(train[train['Gains'] > 60000].index)\n",
    "train = train.drop(train[train['Income'] > 8000].index)\n",
    "\n",
    "# train['working_week_0'] = (train['Working_Week (Yearly)']==0).astype(int)\n",
    "# test['working_week_0'] = (test['Working_Week (Yearly)']==0).astype(int)\n",
    "# \n",
    "# train['working_week_1'] = ((train['Working_Week (Yearly)']>0) & (train['Working_Week (Yearly)']<10)).astype(int)\n",
    "# test['working_week_1'] = ((train['Working_Week (Yearly)']>0) & (train['Working_Week (Yearly)']<10)).astype(int)\n",
    "# \n",
    "# \n",
    "# train['working_week_3'] = ((train['Working_Week (Yearly)']>=45) & (train['Working_Week (Yearly)']<52)).astype(int)\n",
    "# test['working_week_3'] = ((train['Working_Week (Yearly)']>=45) & (train['Working_Week (Yearly)']<52)).astype(int)\n",
    "# \n",
    "# train['working_week_4']=(train['Working_Week (Yearly)']==52).astype(int)\n",
    "# test['working_week_4']=(test['Working_Week (Yearly)']==52).astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:14.299474100Z",
     "start_time": "2024-04-03T12:33:14.273543900Z"
    }
   },
   "id": "3671bfe980ff66bd"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "       Gender_M  Gender_F  Education_Status  Employment_Status  \\\n0             1         0        346.883212         746.928051   \n1             1         0        867.269906         746.928051   \n2             0         1        664.652140         746.928051   \n3             1         0        664.652140         746.928051   \n4             0         1        664.652140         746.928051   \n...         ...       ...               ...                ...   \n19995         1         0        664.652140         488.226979   \n19996         0         1        651.468108         746.928051   \n19997         1         0        651.468108         488.226979   \n19998         0         1        664.652140           0.000000   \n19999         0         1        664.652140         488.226979   \n\n       Industry_Status  Occupation_Status        Race  Hispanic_Origin  \\\n0           608.765668         512.062257  563.554230       574.993697   \n1           703.643885         512.062257  563.554230       574.993697   \n2           739.130826         750.374677  512.730914       574.993697   \n3           527.744681        1002.417563  563.554230       574.993697   \n4           527.744681         488.010638  563.554230       574.993697   \n...                ...                ...         ...              ...   \n19995       907.412063         655.152927  563.554230       574.993697   \n19996       616.393852         750.374677  563.554230       420.946483   \n19997       977.865801        1002.417563  563.554230       574.993697   \n19998         0.000000           0.000000  563.554230       574.993697   \n19999       959.973479         750.374677  563.554230       574.993697   \n\n       Martial_Status  Household_Status  ...  Birth_Country  \\\n0          687.201172        728.328241  ...     560.650659   \n1          632.185780        625.933469  ...     560.650659   \n2          687.201172        728.328241  ...     560.650659   \n3          692.336803        625.933469  ...     560.650659   \n4          692.336803        728.328241  ...     560.650659   \n...               ...               ...  ...            ...   \n19995      368.479404        625.933469  ...     560.650659   \n19996      368.479404        505.561828  ...     560.650659   \n19997      368.479404        452.012766  ...     560.650659   \n19998      324.719577        625.933469  ...     560.650659   \n19999      632.185780        728.328241  ...     560.650659   \n\n       Birth_Country (Father)  Birth_Country (Mother)  Tax_Status  \\\n0                  574.009177              571.103049   60.947341   \n1                  574.009177              571.103049  615.808365   \n2                  574.009177              571.103049  742.472403   \n3                  574.009177              571.103049  615.808365   \n4                  574.009177              571.103049  676.317995   \n...                       ...                     ...         ...   \n19995              574.009177              571.103049  615.808365   \n19996              381.119527              381.285041   60.947341   \n19997              574.009177              571.103049  615.808365   \n19998              443.515864              677.862674  615.808365   \n19999              574.009177              571.103049  676.317995   \n\n       Income_Status  Working_Week (Yearly)  Age  Gains  Losses  Income  \n0         545.810820                      4   63      0       0     425  \n1         537.030294                     52   37      0       0       0  \n2         537.030294                     52   58   3411       0     860  \n3         537.030294                     52   44      0       0     850  \n4         545.810820                     52   37      0       0     570  \n...              ...                    ...  ...    ...     ...     ...  \n19995     537.030294                     52   33      0       0    1300  \n19996     537.030294                     12   20      0       0     850  \n19997     545.810820                     52   22      0       0     999  \n19998     537.030294                      0   76      0       0       0  \n19999     537.030294                     52   41      0       0     671  \n\n[19959 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender_M</th>\n      <th>Gender_F</th>\n      <th>Education_Status</th>\n      <th>Employment_Status</th>\n      <th>Industry_Status</th>\n      <th>Occupation_Status</th>\n      <th>Race</th>\n      <th>Hispanic_Origin</th>\n      <th>Martial_Status</th>\n      <th>Household_Status</th>\n      <th>...</th>\n      <th>Birth_Country</th>\n      <th>Birth_Country (Father)</th>\n      <th>Birth_Country (Mother)</th>\n      <th>Tax_Status</th>\n      <th>Income_Status</th>\n      <th>Working_Week (Yearly)</th>\n      <th>Age</th>\n      <th>Gains</th>\n      <th>Losses</th>\n      <th>Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>346.883212</td>\n      <td>746.928051</td>\n      <td>608.765668</td>\n      <td>512.062257</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>687.201172</td>\n      <td>728.328241</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>60.947341</td>\n      <td>545.810820</td>\n      <td>4</td>\n      <td>63</td>\n      <td>0</td>\n      <td>0</td>\n      <td>425</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>867.269906</td>\n      <td>746.928051</td>\n      <td>703.643885</td>\n      <td>512.062257</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>632.185780</td>\n      <td>625.933469</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>615.808365</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>664.652140</td>\n      <td>746.928051</td>\n      <td>739.130826</td>\n      <td>750.374677</td>\n      <td>512.730914</td>\n      <td>574.993697</td>\n      <td>687.201172</td>\n      <td>728.328241</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>742.472403</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>58</td>\n      <td>3411</td>\n      <td>0</td>\n      <td>860</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>664.652140</td>\n      <td>746.928051</td>\n      <td>527.744681</td>\n      <td>1002.417563</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>692.336803</td>\n      <td>625.933469</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>615.808365</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>44</td>\n      <td>0</td>\n      <td>0</td>\n      <td>850</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>664.652140</td>\n      <td>746.928051</td>\n      <td>527.744681</td>\n      <td>488.010638</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>692.336803</td>\n      <td>728.328241</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>676.317995</td>\n      <td>545.810820</td>\n      <td>52</td>\n      <td>37</td>\n      <td>0</td>\n      <td>0</td>\n      <td>570</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>1</td>\n      <td>0</td>\n      <td>664.652140</td>\n      <td>488.226979</td>\n      <td>907.412063</td>\n      <td>655.152927</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>368.479404</td>\n      <td>625.933469</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>615.808365</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1300</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>0</td>\n      <td>1</td>\n      <td>651.468108</td>\n      <td>746.928051</td>\n      <td>616.393852</td>\n      <td>750.374677</td>\n      <td>563.554230</td>\n      <td>420.946483</td>\n      <td>368.479404</td>\n      <td>505.561828</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>381.119527</td>\n      <td>381.285041</td>\n      <td>60.947341</td>\n      <td>537.030294</td>\n      <td>12</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>850</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>1</td>\n      <td>0</td>\n      <td>651.468108</td>\n      <td>488.226979</td>\n      <td>977.865801</td>\n      <td>1002.417563</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>368.479404</td>\n      <td>452.012766</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>615.808365</td>\n      <td>545.810820</td>\n      <td>52</td>\n      <td>22</td>\n      <td>0</td>\n      <td>0</td>\n      <td>999</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>0</td>\n      <td>1</td>\n      <td>664.652140</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>324.719577</td>\n      <td>625.933469</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>443.515864</td>\n      <td>677.862674</td>\n      <td>615.808365</td>\n      <td>537.030294</td>\n      <td>0</td>\n      <td>76</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19999</th>\n      <td>0</td>\n      <td>1</td>\n      <td>664.652140</td>\n      <td>488.226979</td>\n      <td>959.973479</td>\n      <td>750.374677</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>632.185780</td>\n      <td>728.328241</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>676.317995</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>41</td>\n      <td>0</td>\n      <td>0</td>\n      <td>671</td>\n    </tr>\n  </tbody>\n</table>\n<p>19959 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:15.090998500Z",
     "start_time": "2024-04-03T12:33:15.046073300Z"
    }
   },
   "id": "bf7044c06af5695b"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "      Gender_M  Gender_F  Education_Status  Employment_Status  \\\n0            1         0        483.034146         488.226979   \n1            1         0        325.116719         488.226979   \n2            0         1        483.034146         488.226979   \n3            0         1        867.269906         746.928051   \n4            1         0          0.000000         488.226979   \n...        ...       ...               ...                ...   \n9995         1         0        699.367076         488.226979   \n9996         1         0        651.468108         488.226979   \n9997         1         0        664.652140         488.226979   \n9998         1         0          0.000000         488.226979   \n9999         1         0        664.652140         746.928051   \n\n      Industry_Status  Occupation_Status        Race  Hispanic_Origin  \\\n0            0.000000           0.000000  563.554230       574.993697   \n1            0.000000           0.000000  563.554230       381.213933   \n2          527.744681         512.062257  563.554230       574.993697   \n3          718.083532         512.062257  563.554230       574.993697   \n4            0.000000           0.000000  563.554230       420.946483   \n...               ...                ...         ...              ...   \n9995       747.366876        1002.417563  563.554230       574.993697   \n9996       527.744681         655.152927  563.554230       574.993697   \n9997       527.744681         512.062257  512.730914       574.993697   \n9998         0.000000           0.000000  563.554230       574.993697   \n9999       527.744681         619.179118  563.554230       574.993697   \n\n      Martial_Status  Household_Status  ...  Citizenship  Birth_Country  \\\n0         368.479404        625.933469  ...   560.650659     560.650659   \n1         368.479404        505.561828  ...   560.650659     560.650659   \n2         368.479404        505.561828  ...   560.650659     560.650659   \n3         687.201172        620.124322  ...   560.650659     560.650659   \n4         368.479404         63.779775  ...   560.650659     560.650659   \n...              ...               ...  ...          ...            ...   \n9995      368.479404        625.933469  ...   560.650659     560.650659   \n9996      687.201172        728.328241  ...   560.650659     560.650659   \n9997      368.479404        505.561828  ...   560.650659     560.650659   \n9998      368.479404         63.779775  ...   560.650659     560.650659   \n9999      917.554200        620.124322  ...   560.650659     560.650659   \n\n      Birth_Country (Father)  Birth_Country (Mother)  Tax_Status  \\\n0                 495.955250              532.154739  615.808365   \n1                 574.009177              571.103049   60.947341   \n2                 574.009177              571.103049  615.808365   \n3                 574.009177              571.103049  742.472403   \n4                 574.009177              571.103049   60.947341   \n...                      ...                     ...         ...   \n9995              574.009177              571.103049  615.808365   \n9996              574.009177              571.103049  742.472403   \n9997              574.009177              571.103049   60.947341   \n9998              574.009177              571.103049   60.947341   \n9999              574.009177              571.103049  742.472403   \n\n      Income_Status  Working_Week (Yearly)  Age  Gains  Losses  \n0        537.030294                      0   79      0       0  \n1        537.030294                      0   47      0       0  \n2        537.030294                     52   18      0       0  \n3        545.810820                     30   39      0       0  \n4        545.810820                      0    6      0       0  \n...             ...                    ...  ...    ...     ...  \n9995     537.030294                     52   31      0       0  \n9996     537.030294                     52   27      0       0  \n9997     537.030294                      7   18      0       0  \n9998     537.030294                      0    9      0       0  \n9999     537.030294                     39   34      0       0  \n\n[10000 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender_M</th>\n      <th>Gender_F</th>\n      <th>Education_Status</th>\n      <th>Employment_Status</th>\n      <th>Industry_Status</th>\n      <th>Occupation_Status</th>\n      <th>Race</th>\n      <th>Hispanic_Origin</th>\n      <th>Martial_Status</th>\n      <th>Household_Status</th>\n      <th>...</th>\n      <th>Citizenship</th>\n      <th>Birth_Country</th>\n      <th>Birth_Country (Father)</th>\n      <th>Birth_Country (Mother)</th>\n      <th>Tax_Status</th>\n      <th>Income_Status</th>\n      <th>Working_Week (Yearly)</th>\n      <th>Age</th>\n      <th>Gains</th>\n      <th>Losses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>483.034146</td>\n      <td>488.226979</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>368.479404</td>\n      <td>625.933469</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>495.955250</td>\n      <td>532.154739</td>\n      <td>615.808365</td>\n      <td>537.030294</td>\n      <td>0</td>\n      <td>79</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>325.116719</td>\n      <td>488.226979</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>563.554230</td>\n      <td>381.213933</td>\n      <td>368.479404</td>\n      <td>505.561828</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>60.947341</td>\n      <td>537.030294</td>\n      <td>0</td>\n      <td>47</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>483.034146</td>\n      <td>488.226979</td>\n      <td>527.744681</td>\n      <td>512.062257</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>368.479404</td>\n      <td>505.561828</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>615.808365</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>867.269906</td>\n      <td>746.928051</td>\n      <td>718.083532</td>\n      <td>512.062257</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>687.201172</td>\n      <td>620.124322</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>742.472403</td>\n      <td>545.810820</td>\n      <td>30</td>\n      <td>39</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>488.226979</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>563.554230</td>\n      <td>420.946483</td>\n      <td>368.479404</td>\n      <td>63.779775</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>60.947341</td>\n      <td>545.810820</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>1</td>\n      <td>0</td>\n      <td>699.367076</td>\n      <td>488.226979</td>\n      <td>747.366876</td>\n      <td>1002.417563</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>368.479404</td>\n      <td>625.933469</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>615.808365</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>31</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>1</td>\n      <td>0</td>\n      <td>651.468108</td>\n      <td>488.226979</td>\n      <td>527.744681</td>\n      <td>655.152927</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>687.201172</td>\n      <td>728.328241</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>742.472403</td>\n      <td>537.030294</td>\n      <td>52</td>\n      <td>27</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>1</td>\n      <td>0</td>\n      <td>664.652140</td>\n      <td>488.226979</td>\n      <td>527.744681</td>\n      <td>512.062257</td>\n      <td>512.730914</td>\n      <td>574.993697</td>\n      <td>368.479404</td>\n      <td>505.561828</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>60.947341</td>\n      <td>537.030294</td>\n      <td>7</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>488.226979</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>368.479404</td>\n      <td>63.779775</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>60.947341</td>\n      <td>537.030294</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>1</td>\n      <td>0</td>\n      <td>664.652140</td>\n      <td>746.928051</td>\n      <td>527.744681</td>\n      <td>619.179118</td>\n      <td>563.554230</td>\n      <td>574.993697</td>\n      <td>917.554200</td>\n      <td>620.124322</td>\n      <td>...</td>\n      <td>560.650659</td>\n      <td>560.650659</td>\n      <td>574.009177</td>\n      <td>571.103049</td>\n      <td>742.472403</td>\n      <td>537.030294</td>\n      <td>39</td>\n      <td>34</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:23.881621200Z",
     "start_time": "2024-04-03T12:33:23.835744400Z"
    }
   },
   "id": "ac4488151189e50"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "# train['Income'] = np.log1p(train['Income'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:30.467412400Z",
     "start_time": "2024-04-03T12:33:30.449459400Z"
    }
   },
   "id": "e15c85d7cd3f8119"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "X = train[train.columns.drop('Income')]\n",
    "Y = train['Income']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:30.760372800Z",
     "start_time": "2024-04-03T12:33:30.741423400Z"
    }
   },
   "id": "be33717e69ae5342"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# X와 Y로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:33:31.889721400Z",
     "start_time": "2024-04-03T12:33:31.875759300Z"
    }
   },
   "id": "6aeff8d2a76e0d9d"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-03 21:44:51,894] A new study created in memory with name: no-name-9d3e9b6a-bf03-403b-8a09-18f0809f1e3f\n",
      "[I 2024-04-03 21:44:53,890] Trial 0 finished with value: 543.4112691917474 and parameters: {'learning_rate': 0.0728001054517817, 'n_estimators': 660, 'depth': 4, 'l2_leaf_reg': 4, 'border_count': 214}. Best is trial 0 with value: 543.4112691917474.\n",
      "[I 2024-04-03 21:44:58,016] Trial 1 finished with value: 548.7079342684171 and parameters: {'learning_rate': 0.1578510474175081, 'n_estimators': 778, 'depth': 8, 'l2_leaf_reg': 9, 'border_count': 95}. Best is trial 0 with value: 543.4112691917474.\n",
      "[I 2024-04-03 21:44:58,539] Trial 2 finished with value: 544.7474007521162 and parameters: {'learning_rate': 0.22733864240025778, 'n_estimators': 246, 'depth': 4, 'l2_leaf_reg': 7, 'border_count': 206}. Best is trial 0 with value: 543.4112691917474.\n",
      "[I 2024-04-03 21:44:59,139] Trial 3 finished with value: 541.3771072607667 and parameters: {'learning_rate': 0.28090321129230744, 'n_estimators': 205, 'depth': 6, 'l2_leaf_reg': 10, 'border_count': 129}. Best is trial 3 with value: 541.3771072607667.\n",
      "[I 2024-04-03 21:44:59,987] Trial 4 finished with value: 540.4871940363637 and parameters: {'learning_rate': 0.09550398088949952, 'n_estimators': 136, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 73}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:00,604] Trial 5 finished with value: 541.4146906492967 and parameters: {'learning_rate': 0.13877703667835772, 'n_estimators': 131, 'depth': 8, 'l2_leaf_reg': 10, 'border_count': 68}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:01,741] Trial 6 finished with value: 542.9355035258711 and parameters: {'learning_rate': 0.07784281923379865, 'n_estimators': 415, 'depth': 5, 'l2_leaf_reg': 7, 'border_count': 97}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:04,201] Trial 7 finished with value: 545.0290690921275 and parameters: {'learning_rate': 0.08535312843414873, 'n_estimators': 519, 'depth': 8, 'l2_leaf_reg': 3, 'border_count': 181}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:07,824] Trial 8 finished with value: 557.9305654841137 and parameters: {'learning_rate': 0.18790670205892948, 'n_estimators': 778, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 234}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:10,280] Trial 9 finished with value: 552.0398315876902 and parameters: {'learning_rate': 0.23004212043229316, 'n_estimators': 848, 'depth': 6, 'l2_leaf_reg': 8, 'border_count': 60}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:12,114] Trial 10 finished with value: 542.378745386587 and parameters: {'learning_rate': 0.019352473404620082, 'n_estimators': 340, 'depth': 10, 'l2_leaf_reg': 2, 'border_count': 7}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:13,476] Trial 11 finished with value: 544.4542589864974 and parameters: {'learning_rate': 0.26513191022746985, 'n_estimators': 125, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 158}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:14,316] Trial 12 finished with value: 544.8069047505345 and parameters: {'learning_rate': 0.2974674122654876, 'n_estimators': 269, 'depth': 6, 'l2_leaf_reg': 5, 'border_count': 133}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:15,773] Trial 13 finished with value: 548.6472883937791 and parameters: {'learning_rate': 0.13177060351516012, 'n_estimators': 468, 'depth': 7, 'l2_leaf_reg': 8, 'border_count': 12}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:22,119] Trial 14 finished with value: 540.4927310213192 and parameters: {'learning_rate': 0.013418535765896578, 'n_estimators': 992, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 114}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:27,318] Trial 15 finished with value: 540.7527435843878 and parameters: {'learning_rate': 0.0394585386843519, 'n_estimators': 981, 'depth': 9, 'l2_leaf_reg': 6, 'border_count': 46}. Best is trial 4 with value: 540.4871940363637.\n",
      "[I 2024-04-03 21:45:31,224] Trial 16 finished with value: 539.3866091221032 and parameters: {'learning_rate': 0.04604801604003185, 'n_estimators': 616, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 96}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:45:34,558] Trial 17 finished with value: 555.880124423883 and parameters: {'learning_rate': 0.09769771368801508, 'n_estimators': 648, 'depth': 9, 'l2_leaf_reg': 1, 'border_count': 37}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:45:40,661] Trial 18 finished with value: 541.3013091096993 and parameters: {'learning_rate': 0.052988984917190354, 'n_estimators': 595, 'depth': 10, 'l2_leaf_reg': 5, 'border_count': 86}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:45:42,114] Trial 19 finished with value: 542.074891542804 and parameters: {'learning_rate': 0.11225995909393646, 'n_estimators': 378, 'depth': 7, 'l2_leaf_reg': 7, 'border_count': 149}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:45:45,409] Trial 20 finished with value: 550.1511257565813 and parameters: {'learning_rate': 0.16897390334842824, 'n_estimators': 540, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 72}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:45:51,450] Trial 21 finished with value: 540.7034176461677 and parameters: {'learning_rate': 0.01969723380507396, 'n_estimators': 960, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 110}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:45:57,547] Trial 22 finished with value: 541.1505290238563 and parameters: {'learning_rate': 0.05077386752610234, 'n_estimators': 894, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 113}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:03,054] Trial 23 finished with value: 541.0044480031236 and parameters: {'learning_rate': 0.012152982527607194, 'n_estimators': 737, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 37}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:06,081] Trial 24 finished with value: 543.4564323150781 and parameters: {'learning_rate': 0.05512530889965135, 'n_estimators': 657, 'depth': 8, 'l2_leaf_reg': 7, 'border_count': 159}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:11,435] Trial 25 finished with value: 547.7853736824746 and parameters: {'learning_rate': 0.1104671550463028, 'n_estimators': 869, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 82}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:21,048] Trial 26 finished with value: 540.0688911997922 and parameters: {'learning_rate': 0.03593772311584127, 'n_estimators': 733, 'depth': 10, 'l2_leaf_reg': 6, 'border_count': 111}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:28,130] Trial 27 finished with value: 544.1512155424848 and parameters: {'learning_rate': 0.0419728296312539, 'n_estimators': 716, 'depth': 10, 'l2_leaf_reg': 4, 'border_count': 56}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:32,069] Trial 28 finished with value: 545.1321857613433 and parameters: {'learning_rate': 0.06768826820990417, 'n_estimators': 589, 'depth': 10, 'l2_leaf_reg': 6, 'border_count': 24}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:33,922] Trial 29 finished with value: 542.6939068842636 and parameters: {'learning_rate': 0.09449806845308656, 'n_estimators': 478, 'depth': 7, 'l2_leaf_reg': 4, 'border_count': 185}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:41,450] Trial 30 finished with value: 548.4163423650623 and parameters: {'learning_rate': 0.07142733423642701, 'n_estimators': 711, 'depth': 10, 'l2_leaf_reg': 5, 'border_count': 144}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:47,340] Trial 31 finished with value: 540.049123588162 and parameters: {'learning_rate': 0.030091721317324717, 'n_estimators': 930, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 109}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:51,002] Trial 32 finished with value: 540.5840503344436 and parameters: {'learning_rate': 0.03268344092894847, 'n_estimators': 806, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 102}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:56,845] Trial 33 finished with value: 542.5526861815422 and parameters: {'learning_rate': 0.06146103852646506, 'n_estimators': 929, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 82}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:46:59,736] Trial 34 finished with value: 541.0299975817312 and parameters: {'learning_rate': 0.031517355323400324, 'n_estimators': 602, 'depth': 8, 'l2_leaf_reg': 8, 'border_count': 127}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:01,449] Trial 35 finished with value: 543.1200183320793 and parameters: {'learning_rate': 0.11423028550934278, 'n_estimators': 797, 'depth': 4, 'l2_leaf_reg': 7, 'border_count': 121}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:02,585] Trial 36 finished with value: 539.9656163897672 and parameters: {'learning_rate': 0.08128743328915311, 'n_estimators': 176, 'depth': 9, 'l2_leaf_reg': 6, 'border_count': 92}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:05,630] Trial 37 finished with value: 541.1257880097226 and parameters: {'learning_rate': 0.029784693412603713, 'n_estimators': 293, 'depth': 10, 'l2_leaf_reg': 5, 'border_count': 99}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:08,899] Trial 38 finished with value: 543.5309723582595 and parameters: {'learning_rate': 0.07972407012670302, 'n_estimators': 679, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 137}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:09,424] Trial 39 finished with value: 544.7594254959519 and parameters: {'learning_rate': 0.04678197688069757, 'n_estimators': 187, 'depth': 5, 'l2_leaf_reg': 3, 'border_count': 96}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:12,229] Trial 40 finished with value: 545.1336527245388 and parameters: {'learning_rate': 0.13116965327982533, 'n_estimators': 429, 'depth': 9, 'l2_leaf_reg': 6, 'border_count': 165}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:13,493] Trial 41 finished with value: 540.5001095411575 and parameters: {'learning_rate': 0.0901362999121115, 'n_estimators': 204, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 72}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:15,042] Trial 42 finished with value: 541.0860947064627 and parameters: {'learning_rate': 0.07050307148296084, 'n_estimators': 152, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 87}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:16,950] Trial 43 finished with value: 547.7890625610274 and parameters: {'learning_rate': 0.1919701854990675, 'n_estimators': 327, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 66}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:17,487] Trial 44 finished with value: 540.3953488542383 and parameters: {'learning_rate': 0.14307667032867288, 'n_estimators': 110, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 105}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:18,004] Trial 45 finished with value: 543.0674881374525 and parameters: {'learning_rate': 0.15321558778120042, 'n_estimators': 106, 'depth': 8, 'l2_leaf_reg': 5, 'border_count': 106}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:18,863] Trial 46 finished with value: 545.471463451367 and parameters: {'learning_rate': 0.21584368336458243, 'n_estimators': 171, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 119}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:19,752] Trial 47 finished with value: 543.6651816088809 and parameters: {'learning_rate': 0.025901084123290757, 'n_estimators': 234, 'depth': 7, 'l2_leaf_reg': 4, 'border_count': 90}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:23,019] Trial 48 finished with value: 540.1344978730782 and parameters: {'learning_rate': 0.061434258827406246, 'n_estimators': 513, 'depth': 9, 'l2_leaf_reg': 6, 'border_count': 127}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:31,434] Trial 49 finished with value: 544.7514984151807 and parameters: {'learning_rate': 0.06075896719458443, 'n_estimators': 763, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 132}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:36,665] Trial 50 finished with value: 541.5807730212023 and parameters: {'learning_rate': 0.03753088179165817, 'n_estimators': 824, 'depth': 9, 'l2_leaf_reg': 5, 'border_count': 188}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:38,967] Trial 51 finished with value: 542.3822737896758 and parameters: {'learning_rate': 0.08429099960527203, 'n_estimators': 495, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 248}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:42,856] Trial 52 finished with value: 544.6677029539604 and parameters: {'learning_rate': 0.10334817615133626, 'n_estimators': 619, 'depth': 9, 'l2_leaf_reg': 6, 'border_count': 122}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:45,430] Trial 53 finished with value: 541.4489657588808 and parameters: {'learning_rate': 0.044177880519147665, 'n_estimators': 565, 'depth': 8, 'l2_leaf_reg': 7, 'border_count': 145}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:48,165] Trial 54 finished with value: 542.0833084652273 and parameters: {'learning_rate': 0.12620939424498953, 'n_estimators': 241, 'depth': 10, 'l2_leaf_reg': 5, 'border_count': 107}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:50,591] Trial 55 finished with value: 547.586950496821 and parameters: {'learning_rate': 0.14961197494765557, 'n_estimators': 428, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 56}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:56,694] Trial 56 finished with value: 560.1846227254857 and parameters: {'learning_rate': 0.17141587638841416, 'n_estimators': 905, 'depth': 9, 'l2_leaf_reg': 6, 'border_count': 80}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:47:58,827] Trial 57 finished with value: 542.221234257784 and parameters: {'learning_rate': 0.02019609019814302, 'n_estimators': 548, 'depth': 7, 'l2_leaf_reg': 10, 'border_count': 97}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:03,011] Trial 58 finished with value: 544.6360991677686 and parameters: {'learning_rate': 0.010853598589109562, 'n_estimators': 363, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 114}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:07,286] Trial 59 finished with value: 540.009822565998 and parameters: {'learning_rate': 0.06165066111410901, 'n_estimators': 682, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 172}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:11,850] Trial 60 finished with value: 539.9330883979386 and parameters: {'learning_rate': 0.052413315974073546, 'n_estimators': 695, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 165}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:16,373] Trial 61 finished with value: 542.4622067044002 and parameters: {'learning_rate': 0.05856534578765048, 'n_estimators': 696, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 208}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:21,145] Trial 62 finished with value: 543.0517077684777 and parameters: {'learning_rate': 0.07687113458004956, 'n_estimators': 756, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 194}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:25,469] Trial 63 finished with value: 541.0022706200496 and parameters: {'learning_rate': 0.04398304867460989, 'n_estimators': 635, 'depth': 9, 'l2_leaf_reg': 10, 'border_count': 164}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:33,644] Trial 64 finished with value: 540.7858968338614 and parameters: {'learning_rate': 0.05256121241433849, 'n_estimators': 669, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 153}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:39,205] Trial 65 finished with value: 540.667147627838 and parameters: {'learning_rate': 0.025585337908847625, 'n_estimators': 860, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 139}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:44,809] Trial 66 finished with value: 543.1704638666915 and parameters: {'learning_rate': 0.06624084043044848, 'n_estimators': 521, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 125}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:53,313] Trial 67 finished with value: 542.6116521142228 and parameters: {'learning_rate': 0.03808537885433775, 'n_estimators': 731, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 174}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:48:57,357] Trial 68 finished with value: 540.5597042685459 and parameters: {'learning_rate': 0.053472382247690346, 'n_estimators': 567, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 224}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:49:00,684] Trial 69 finished with value: 542.9870920036161 and parameters: {'learning_rate': 0.07565954202365771, 'n_estimators': 631, 'depth': 8, 'l2_leaf_reg': 7, 'border_count': 198}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:49:05,686] Trial 70 finished with value: 543.2176541261853 and parameters: {'learning_rate': 0.08663774634505825, 'n_estimators': 688, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 177}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:49:06,259] Trial 71 finished with value: 542.8839965550784 and parameters: {'learning_rate': 0.06254410608131629, 'n_estimators': 100, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 115}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:49:10,975] Trial 72 finished with value: 541.7708172328098 and parameters: {'learning_rate': 0.0364357702464452, 'n_estimators': 940, 'depth': 8, 'l2_leaf_reg': 6, 'border_count': 105}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:49:15,939] Trial 73 finished with value: 569.5023195146907 and parameters: {'learning_rate': 0.2605611205774655, 'n_estimators': 741, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 92}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:49:16,694] Trial 74 finished with value: 542.3385648257512 and parameters: {'learning_rate': 0.10202026059819091, 'n_estimators': 140, 'depth': 8, 'l2_leaf_reg': 5, 'border_count': 135}. Best is trial 16 with value: 539.3866091221032.\n",
      "[I 2024-04-03 21:49:21,933] Trial 75 finished with value: 539.2790086694687 and parameters: {'learning_rate': 0.02328493153604938, 'n_estimators': 777, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 171}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:49:29,128] Trial 76 finished with value: 539.6185478205932 and parameters: {'learning_rate': 0.017276414718630374, 'n_estimators': 815, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 169}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:49:35,112] Trial 77 finished with value: 539.7748438870524 and parameters: {'learning_rate': 0.019899092764136355, 'n_estimators': 833, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 170}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:49:41,021] Trial 78 finished with value: 540.2451301677149 and parameters: {'learning_rate': 0.01662935243705281, 'n_estimators': 841, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 170}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:49:48,029] Trial 79 finished with value: 540.4614542138264 and parameters: {'learning_rate': 0.02383391172597278, 'n_estimators': 804, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 158}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:49:50,418] Trial 80 finished with value: 545.13025741762 and parameters: {'learning_rate': 0.010217553439785775, 'n_estimators': 776, 'depth': 5, 'l2_leaf_reg': 7, 'border_count': 183}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:49:56,646] Trial 81 finished with value: 540.0796398782204 and parameters: {'learning_rate': 0.03476216312734794, 'n_estimators': 887, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 168}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:50:02,445] Trial 82 finished with value: 540.4073848490046 and parameters: {'learning_rate': 0.028578878427238125, 'n_estimators': 831, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 152}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:50:10,731] Trial 83 finished with value: 540.6499786490049 and parameters: {'learning_rate': 0.046993017104509024, 'n_estimators': 720, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 194}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:50:15,244] Trial 84 finished with value: 540.5982887333913 and parameters: {'learning_rate': 0.019414308365667578, 'n_estimators': 658, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 162}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:50:24,634] Trial 85 finished with value: 540.0618192395457 and parameters: {'learning_rate': 0.027334083776839786, 'n_estimators': 786, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 175}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:50:30,243] Trial 86 finished with value: 539.7053046225122 and parameters: {'learning_rate': 0.029815954951980285, 'n_estimators': 786, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 176}. Best is trial 75 with value: 539.2790086694687.\n",
      "[I 2024-04-03 21:50:37,261] Trial 87 finished with value: 539.1627242404049 and parameters: {'learning_rate': 0.017958784875726583, 'n_estimators': 985, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 202}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:50:42,039] Trial 88 finished with value: 541.2460316957389 and parameters: {'learning_rate': 0.04682449966420309, 'n_estimators': 705, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 214}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:50:47,021] Trial 89 finished with value: 540.4329903618867 and parameters: {'learning_rate': 0.01799807038160402, 'n_estimators': 746, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 200}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:50:53,825] Trial 90 finished with value: 545.4729842431261 and parameters: {'learning_rate': 0.04076852412031273, 'n_estimators': 983, 'depth': 9, 'l2_leaf_reg': 1, 'border_count': 187}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:00,342] Trial 91 finished with value: 540.8709217265164 and parameters: {'learning_rate': 0.02837144404143121, 'n_estimators': 953, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 180}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:06,601] Trial 92 finished with value: 539.8885601938359 and parameters: {'learning_rate': 0.021210712679856247, 'n_estimators': 907, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 207}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:12,594] Trial 93 finished with value: 540.091110914405 and parameters: {'learning_rate': 0.014749739134982448, 'n_estimators': 905, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 211}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:18,257] Trial 94 finished with value: 540.0358767282598 and parameters: {'learning_rate': 0.020778644485018587, 'n_estimators': 860, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 231}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:23,906] Trial 95 finished with value: 541.6830837277553 and parameters: {'learning_rate': 0.053380615239510966, 'n_estimators': 818, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 203}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:29,944] Trial 96 finished with value: 540.6979981096413 and parameters: {'learning_rate': 0.03284786228102182, 'n_estimators': 880, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 226}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:35,483] Trial 97 finished with value: 541.760517447419 and parameters: {'learning_rate': 0.01096624758707732, 'n_estimators': 774, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 192}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:40,971] Trial 98 finished with value: 541.0748413207282 and parameters: {'learning_rate': 0.04499260575159584, 'n_estimators': 966, 'depth': 8, 'l2_leaf_reg': 10, 'border_count': 217}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:47,257] Trial 99 finished with value: 539.6131396268635 and parameters: {'learning_rate': 0.025119330494083054, 'n_estimators': 906, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 157}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:53,819] Trial 100 finished with value: 540.6743077681027 and parameters: {'learning_rate': 0.02410523665904512, 'n_estimators': 1000, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 144}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:51:59,438] Trial 101 finished with value: 541.2132264501183 and parameters: {'learning_rate': 0.038806489069122915, 'n_estimators': 847, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 155}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:02,447] Trial 102 finished with value: 541.6956034675312 and parameters: {'learning_rate': 0.018533283538613707, 'n_estimators': 920, 'depth': 6, 'l2_leaf_reg': 7, 'border_count': 173}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:08,153] Trial 103 finished with value: 540.2151756383771 and parameters: {'learning_rate': 0.032064258713246356, 'n_estimators': 812, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 168}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:14,116] Trial 104 finished with value: 543.2562299893428 and parameters: {'learning_rate': 0.0496484247077941, 'n_estimators': 900, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 180}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:18,113] Trial 105 finished with value: 539.35734806768 and parameters: {'learning_rate': 0.05854109752714415, 'n_estimators': 610, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 162}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:22,088] Trial 106 finished with value: 540.4807841123777 and parameters: {'learning_rate': 0.03925986662531314, 'n_estimators': 600, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 160}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:27,865] Trial 107 finished with value: 544.1529395135173 and parameters: {'learning_rate': 0.06776808219924857, 'n_estimators': 874, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 244}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:32,630] Trial 108 finished with value: 540.8326173184201 and parameters: {'learning_rate': 0.015017787313057234, 'n_estimators': 926, 'depth': 8, 'l2_leaf_reg': 2, 'border_count': 148}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:41,319] Trial 109 finished with value: 539.5658039231455 and parameters: {'learning_rate': 0.023538222860977863, 'n_estimators': 790, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 165}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:49,755] Trial 110 finished with value: 539.437740391832 and parameters: {'learning_rate': 0.0233738596759897, 'n_estimators': 760, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 188}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:52:59,079] Trial 111 finished with value: 539.4699349981878 and parameters: {'learning_rate': 0.02110855671427376, 'n_estimators': 851, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 189}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:53:08,362] Trial 112 finished with value: 540.137040765027 and parameters: {'learning_rate': 0.022877127832059932, 'n_estimators': 835, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 187}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:53:16,865] Trial 113 finished with value: 539.332310655457 and parameters: {'learning_rate': 0.029979668425429554, 'n_estimators': 789, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 191}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:53:26,783] Trial 114 finished with value: 540.4887889465311 and parameters: {'learning_rate': 0.030529688397523583, 'n_estimators': 792, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 190}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:53:36,065] Trial 115 finished with value: 542.0825970903649 and parameters: {'learning_rate': 0.010091253820517749, 'n_estimators': 771, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 197}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:53:45,284] Trial 116 finished with value: 539.8475125553734 and parameters: {'learning_rate': 0.03489370232917942, 'n_estimators': 754, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 181}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:53:55,241] Trial 117 finished with value: 539.8510074369651 and parameters: {'learning_rate': 0.016110246247743966, 'n_estimators': 852, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 178}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:54:04,296] Trial 118 finished with value: 539.3864445073434 and parameters: {'learning_rate': 0.02551239399459321, 'n_estimators': 800, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 185}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:54:13,427] Trial 119 finished with value: 539.6948482325282 and parameters: {'learning_rate': 0.024988246672247267, 'n_estimators': 812, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 202}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:54:22,483] Trial 120 finished with value: 540.466944001228 and parameters: {'learning_rate': 0.04083414421415416, 'n_estimators': 806, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 202}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:54:31,485] Trial 121 finished with value: 540.3305570433457 and parameters: {'learning_rate': 0.025267681251384042, 'n_estimators': 792, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 185}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:54:41,145] Trial 122 finished with value: 539.7704567706935 and parameters: {'learning_rate': 0.03027593387732772, 'n_estimators': 819, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 193}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:54:49,172] Trial 123 finished with value: 539.803936130939 and parameters: {'learning_rate': 0.0254690789312959, 'n_estimators': 725, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 220}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:54:57,648] Trial 124 finished with value: 539.7692971863002 and parameters: {'learning_rate': 0.03284520571687279, 'n_estimators': 763, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 175}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:55:06,564] Trial 125 finished with value: 540.5408501035813 and parameters: {'learning_rate': 0.04223954277754963, 'n_estimators': 783, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 206}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:55:15,601] Trial 126 finished with value: 540.4990311959268 and parameters: {'learning_rate': 0.016596246207234766, 'n_estimators': 801, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 165}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:55:23,948] Trial 127 finished with value: 539.7485041985966 and parameters: {'learning_rate': 0.02682784579073065, 'n_estimators': 743, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 197}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:55:33,986] Trial 128 finished with value: 541.3721962900227 and parameters: {'learning_rate': 0.010140286141923634, 'n_estimators': 871, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 184}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:55:43,708] Trial 129 finished with value: 539.9357339723206 and parameters: {'learning_rate': 0.035858926376614954, 'n_estimators': 847, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 190}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:55:50,172] Trial 130 finished with value: 542.5528880799819 and parameters: {'learning_rate': 0.05664283236512542, 'n_estimators': 579, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 162}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:55:58,485] Trial 131 finished with value: 540.6863495251068 and parameters: {'learning_rate': 0.026155546271496626, 'n_estimators': 749, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 196}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:56:07,305] Trial 132 finished with value: 540.3089704639652 and parameters: {'learning_rate': 0.02294428013926782, 'n_estimators': 768, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 202}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:56:16,712] Trial 133 finished with value: 540.4000255041342 and parameters: {'learning_rate': 0.015838266798467115, 'n_estimators': 827, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 178}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:56:25,669] Trial 134 finished with value: 540.5421069650497 and parameters: {'learning_rate': 0.030076446954438844, 'n_estimators': 791, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 155}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:56:32,671] Trial 135 finished with value: 541.700324281452 and parameters: {'learning_rate': 0.0470789619850161, 'n_estimators': 615, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 210}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:56:41,487] Trial 136 finished with value: 539.6220172164028 and parameters: {'learning_rate': 0.035972732165586684, 'n_estimators': 734, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 171}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:56:50,659] Trial 137 finished with value: 540.232125597058 and parameters: {'learning_rate': 0.037178446410742264, 'n_estimators': 815, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 166}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:56:58,750] Trial 138 finished with value: 542.0027094064134 and parameters: {'learning_rate': 0.042969319564423736, 'n_estimators': 705, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 172}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:57:06,037] Trial 139 finished with value: 540.1563200698415 and parameters: {'learning_rate': 0.019740521463543825, 'n_estimators': 647, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 140}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:57:14,538] Trial 140 finished with value: 540.2427196702589 and parameters: {'learning_rate': 0.029524744487173533, 'n_estimators': 724, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 183}. Best is trial 87 with value: 539.1627242404049.\n",
      "[I 2024-04-03 21:57:22,767] Trial 141 finished with value: 539.1594642145907 and parameters: {'learning_rate': 0.02441895956892351, 'n_estimators': 740, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 188}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:57:31,296] Trial 142 finished with value: 540.2473897825407 and parameters: {'learning_rate': 0.021281719104122687, 'n_estimators': 762, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 190}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:57:40,740] Trial 143 finished with value: 540.394408537817 and parameters: {'learning_rate': 0.034562794624515426, 'n_estimators': 785, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 177}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:57:48,533] Trial 144 finished with value: 564.892753374096 and parameters: {'learning_rate': 0.20633211576398808, 'n_estimators': 678, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 150}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:57:56,785] Trial 145 finished with value: 540.6300828604701 and parameters: {'learning_rate': 0.01549989891519036, 'n_estimators': 732, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 159}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:05,955] Trial 146 finished with value: 540.0900616547842 and parameters: {'learning_rate': 0.023496378458057916, 'n_estimators': 807, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 171}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:15,827] Trial 147 finished with value: 542.0251323426089 and parameters: {'learning_rate': 0.04879601652951816, 'n_estimators': 833, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 181}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:17,840] Trial 148 finished with value: 542.9629023406217 and parameters: {'learning_rate': 0.03938889615101919, 'n_estimators': 853, 'depth': 4, 'l2_leaf_reg': 7, 'border_count': 190}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:26,646] Trial 149 finished with value: 540.2253961062056 and parameters: {'learning_rate': 0.03276923553957372, 'n_estimators': 775, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 187}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:33,153] Trial 150 finished with value: 540.0884606037001 and parameters: {'learning_rate': 0.014026368215356647, 'n_estimators': 965, 'depth': 9, 'l2_leaf_reg': 10, 'border_count': 202}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:42,157] Trial 151 finished with value: 540.2662112534879 and parameters: {'learning_rate': 0.027173472500041578, 'n_estimators': 751, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 196}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:50,627] Trial 152 finished with value: 579.986009003024 and parameters: {'learning_rate': 0.2966598455848998, 'n_estimators': 739, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 214}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:58:58,953] Trial 153 finished with value: 568.3700311430373 and parameters: {'learning_rate': 0.2529131106603802, 'n_estimators': 715, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 199}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:01,927] Trial 154 finished with value: 540.6869758069411 and parameters: {'learning_rate': 0.02837653532139865, 'n_estimators': 790, 'depth': 7, 'l2_leaf_reg': 8, 'border_count': 184}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:10,464] Trial 155 finished with value: 541.2169701078395 and parameters: {'learning_rate': 0.019563715891270553, 'n_estimators': 759, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 169}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:19,511] Trial 156 finished with value: 540.6689692648839 and parameters: {'learning_rate': 0.02511551409148684, 'n_estimators': 803, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 206}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:25,774] Trial 157 finished with value: 540.1929113173867 and parameters: {'learning_rate': 0.03784043330366058, 'n_estimators': 946, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 176}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:34,647] Trial 158 finished with value: 541.4437528779151 and parameters: {'learning_rate': 0.010927521429418847, 'n_estimators': 819, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 196}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:40,858] Trial 159 finished with value: 559.3494291821793 and parameters: {'learning_rate': 0.16394155556109305, 'n_estimators': 886, 'depth': 9, 'l2_leaf_reg': 8, 'border_count': 156}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:44,580] Trial 160 finished with value: 540.0343291146814 and parameters: {'learning_rate': 0.033107002937194006, 'n_estimators': 537, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 192}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:53,235] Trial 161 finished with value: 541.3736752131832 and parameters: {'learning_rate': 0.03218598175472563, 'n_estimators': 776, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 175}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 21:59:59,582] Trial 162 finished with value: 540.5723256945847 and parameters: {'learning_rate': 0.021891208465860942, 'n_estimators': 757, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 45}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:00:08,042] Trial 163 finished with value: 540.378153965317 and parameters: {'learning_rate': 0.027813745483160807, 'n_estimators': 737, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 174}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:00:16,354] Trial 164 finished with value: 540.9892218640235 and parameters: {'learning_rate': 0.040273579420440964, 'n_estimators': 704, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 162}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:00:25,217] Trial 165 finished with value: 540.6027079731927 and parameters: {'learning_rate': 0.04498253158726091, 'n_estimators': 776, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 182}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:00:34,175] Trial 166 finished with value: 540.1430266503096 and parameters: {'learning_rate': 0.017942812665987493, 'n_estimators': 803, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 168}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:00:42,966] Trial 167 finished with value: 541.2936664561689 and parameters: {'learning_rate': 0.03431533720244668, 'n_estimators': 746, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 177}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:00:48,695] Trial 168 finished with value: 540.9108556407947 and parameters: {'learning_rate': 0.025845668473329003, 'n_estimators': 839, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 186}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:00:58,065] Trial 169 finished with value: 540.0196695216969 and parameters: {'learning_rate': 0.01657127207736603, 'n_estimators': 864, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 164}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:01:03,621] Trial 170 finished with value: 540.2328675755167 and parameters: {'learning_rate': 0.05333401116039817, 'n_estimators': 825, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 194}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:01:13,175] Trial 171 finished with value: 539.7515652655991 and parameters: {'learning_rate': 0.03018652741045312, 'n_estimators': 819, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 191}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:01:15,864] Trial 172 finished with value: 542.4376944249697 and parameters: {'learning_rate': 0.031060081272086863, 'n_estimators': 769, 'depth': 6, 'l2_leaf_reg': 10, 'border_count': 188}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:01:24,690] Trial 173 finished with value: 540.3289860810886 and parameters: {'learning_rate': 0.022001528627098824, 'n_estimators': 796, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 200}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:01:34,034] Trial 174 finished with value: 539.6133232733379 and parameters: {'learning_rate': 0.035585627433569085, 'n_estimators': 815, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 180}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:01:43,678] Trial 175 finished with value: 541.0442710665762 and parameters: {'learning_rate': 0.04214004153447189, 'n_estimators': 812, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 180}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:01:53,343] Trial 176 finished with value: 541.1778740381305 and parameters: {'learning_rate': 0.010470032051906875, 'n_estimators': 847, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 206}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:02,893] Trial 177 finished with value: 552.2168491781773 and parameters: {'learning_rate': 0.1206345391677873, 'n_estimators': 827, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 192}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:08,112] Trial 178 finished with value: 539.9156078051741 and parameters: {'learning_rate': 0.024815771895770194, 'n_estimators': 781, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 171}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:18,296] Trial 179 finished with value: 540.2644100541662 and parameters: {'learning_rate': 0.017361253756661144, 'n_estimators': 864, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 187}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:27,287] Trial 180 finished with value: 542.4175716921116 and parameters: {'learning_rate': 0.03683866906524948, 'n_estimators': 796, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 198}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:32,655] Trial 181 finished with value: 540.4116192633777 and parameters: {'learning_rate': 0.030964735186241002, 'n_estimators': 474, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 173}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:40,845] Trial 182 finished with value: 539.8624078037668 and parameters: {'learning_rate': 0.027401848473432855, 'n_estimators': 723, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 183}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:49,615] Trial 183 finished with value: 540.9492583429617 and parameters: {'learning_rate': 0.03507932057572585, 'n_estimators': 751, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 167}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:02:58,240] Trial 184 finished with value: 541.8361646124436 and parameters: {'learning_rate': 0.04599608775770092, 'n_estimators': 766, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 179}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:03:03,515] Trial 185 finished with value: 539.9709694684592 and parameters: {'learning_rate': 0.021457132251189344, 'n_estimators': 814, 'depth': 9, 'l2_leaf_reg': 10, 'border_count': 191}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:03:12,466] Trial 186 finished with value: 540.1810813458109 and parameters: {'learning_rate': 0.029246013417066834, 'n_estimators': 783, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 162}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:03:23,824] Trial 187 finished with value: 542.256062691006 and parameters: {'learning_rate': 0.04032991561884733, 'n_estimators': 981, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 184}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:03:29,336] Trial 188 finished with value: 540.1457373262275 and parameters: {'learning_rate': 0.015348877874652254, 'n_estimators': 840, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 176}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:03:37,756] Trial 189 finished with value: 539.9538851349263 and parameters: {'learning_rate': 0.02391179272483467, 'n_estimators': 740, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 202}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:03:45,536] Trial 190 finished with value: 540.5115238940808 and parameters: {'learning_rate': 0.03356915421879418, 'n_estimators': 667, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 213}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:03:54,977] Trial 191 finished with value: 539.2451858194864 and parameters: {'learning_rate': 0.029407431941751473, 'n_estimators': 827, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 192}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:03,725] Trial 192 finished with value: 539.6492626722427 and parameters: {'learning_rate': 0.020777279789149384, 'n_estimators': 798, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 189}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:12,777] Trial 193 finished with value: 539.4351479888682 and parameters: {'learning_rate': 0.021417758847174208, 'n_estimators': 814, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 196}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:21,948] Trial 194 finished with value: 540.4687271791505 and parameters: {'learning_rate': 0.014904413621917967, 'n_estimators': 797, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 198}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:31,648] Trial 195 finished with value: 540.2479545744678 and parameters: {'learning_rate': 0.02013931774651164, 'n_estimators': 880, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 206}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:37,200] Trial 196 finished with value: 539.999236181351 and parameters: {'learning_rate': 0.02380746736595616, 'n_estimators': 842, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 194}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:43,126] Trial 197 finished with value: 539.5423546776755 and parameters: {'learning_rate': 0.019530851246857987, 'n_estimators': 792, 'depth': 10, 'l2_leaf_reg': 6, 'border_count': 25}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:51,585] Trial 198 finished with value: 540.2143317973145 and parameters: {'learning_rate': 0.014305790021004617, 'n_estimators': 806, 'depth': 10, 'l2_leaf_reg': 6, 'border_count': 66}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:04:56,079] Trial 199 finished with value: 540.734165740718 and parameters: {'learning_rate': 0.02026633478150233, 'n_estimators': 915, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 28}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:05,504] Trial 200 finished with value: 565.9443660498642 and parameters: {'learning_rate': 0.17849603885314116, 'n_estimators': 826, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 158}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:10,721] Trial 201 finished with value: 539.5204428836331 and parameters: {'learning_rate': 0.025807457870252053, 'n_estimators': 788, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 16}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:15,500] Trial 202 finished with value: 542.4283707386861 and parameters: {'learning_rate': 0.020479398152391567, 'n_estimators': 783, 'depth': 10, 'l2_leaf_reg': 6, 'border_count': 8}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:24,763] Trial 203 finished with value: 540.011347833839 and parameters: {'learning_rate': 0.02756184368937617, 'n_estimators': 798, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 183}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:30,283] Trial 204 finished with value: 540.9281632021655 and parameters: {'learning_rate': 0.01113537758481608, 'n_estimators': 819, 'depth': 10, 'l2_leaf_reg': 5, 'border_count': 18}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:34,210] Trial 205 finished with value: 549.5006213323949 and parameters: {'learning_rate': 0.03670354338766878, 'n_estimators': 781, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 3}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:41,292] Trial 206 finished with value: 540.7316604460196 and parameters: {'learning_rate': 0.022702183750644745, 'n_estimators': 860, 'depth': 10, 'l2_leaf_reg': 6, 'border_count': 37}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:46,974] Trial 207 finished with value: 540.2741710698554 and parameters: {'learning_rate': 0.018291882507879987, 'n_estimators': 767, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 20}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:05:52,750] Trial 208 finished with value: 541.41564765771 and parameters: {'learning_rate': 0.027252915326644804, 'n_estimators': 834, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 186}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:01,871] Trial 209 finished with value: 540.8960287640574 and parameters: {'learning_rate': 0.010000197224502183, 'n_estimators': 800, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 170}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:07,394] Trial 210 finished with value: 540.6858716141205 and parameters: {'learning_rate': 0.03274532883928072, 'n_estimators': 807, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 20}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:16,056] Trial 211 finished with value: 541.0712688387493 and parameters: {'learning_rate': 0.02589944054659329, 'n_estimators': 755, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 196}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:23,498] Trial 212 finished with value: 540.0279800322071 and parameters: {'learning_rate': 0.0186636986818604, 'n_estimators': 779, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 59}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:28,482] Trial 213 finished with value: 542.2271950878945 and parameters: {'learning_rate': 0.02749027544278307, 'n_estimators': 794, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 10}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:32,716] Trial 214 finished with value: 541.2683888774934 and parameters: {'learning_rate': 0.03782268739907097, 'n_estimators': 624, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 15}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:41,251] Trial 215 finished with value: 539.8147476095269 and parameters: {'learning_rate': 0.023690010497438525, 'n_estimators': 761, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 189}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:47,481] Trial 216 finished with value: 540.127970573265 and parameters: {'learning_rate': 0.014985163478269075, 'n_estimators': 815, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 26}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:06:52,563] Trial 217 finished with value: 541.8269660564952 and parameters: {'learning_rate': 0.031685161305723394, 'n_estimators': 730, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 202}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:07:00,886] Trial 218 finished with value: 541.0591669662128 and parameters: {'learning_rate': 0.042612566969016816, 'n_estimators': 786, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 74}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:07:06,690] Trial 219 finished with value: 540.174238477327 and parameters: {'learning_rate': 0.023221995373209223, 'n_estimators': 848, 'depth': 9, 'l2_leaf_reg': 4, 'border_count': 181}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:07:13,099] Trial 220 finished with value: 541.8684673322027 and parameters: {'learning_rate': 0.028268870541384664, 'n_estimators': 823, 'depth': 10, 'l2_leaf_reg': 8, 'border_count': 31}. Best is trial 141 with value: 539.1594642145907.\n",
      "[I 2024-04-03 22:07:19,998] Trial 221 finished with value: 539.1559899618396 and parameters: {'learning_rate': 0.03187248081074932, 'n_estimators': 578, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 192}. Best is trial 221 with value: 539.1559899618396.\n",
      "[I 2024-04-03 22:07:26,779] Trial 222 finished with value: 538.9357725249145 and parameters: {'learning_rate': 0.03638522220901159, 'n_estimators': 586, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 194}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:07:33,777] Trial 223 finished with value: 539.2948806154421 and parameters: {'learning_rate': 0.036273569044942215, 'n_estimators': 608, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 189}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:07:40,434] Trial 224 finished with value: 539.8667656465412 and parameters: {'learning_rate': 0.03691054531208747, 'n_estimators': 584, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 194}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:07:46,904] Trial 225 finished with value: 540.9147620459415 and parameters: {'learning_rate': 0.04497111378273569, 'n_estimators': 544, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 192}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:07:54,244] Trial 226 finished with value: 539.6801464361536 and parameters: {'learning_rate': 0.04965699203818388, 'n_estimators': 608, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 200}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:01,265] Trial 227 finished with value: 541.5754879906198 and parameters: {'learning_rate': 0.047346159724854446, 'n_estimators': 604, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 188}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:07,765] Trial 228 finished with value: 540.9078914725133 and parameters: {'learning_rate': 0.05389313764533131, 'n_estimators': 564, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 199}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:14,921] Trial 229 finished with value: 543.4209081064606 and parameters: {'learning_rate': 0.0592560435484948, 'n_estimators': 643, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 187}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:22,330] Trial 230 finished with value: 540.9942589957814 and parameters: {'learning_rate': 0.04117196281239353, 'n_estimators': 609, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 195}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:29,161] Trial 231 finished with value: 539.8712382341864 and parameters: {'learning_rate': 0.034290931802440555, 'n_estimators': 588, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 207}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:35,820] Trial 232 finished with value: 540.0420240510097 and parameters: {'learning_rate': 0.04938309437954678, 'n_estimators': 572, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 201}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:42,752] Trial 233 finished with value: 540.925763950288 and parameters: {'learning_rate': 0.019162034146768717, 'n_estimators': 622, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 192}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:49,729] Trial 234 finished with value: 540.3187112111972 and parameters: {'learning_rate': 0.033649882044077095, 'n_estimators': 584, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 187}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:08:56,732] Trial 235 finished with value: 540.1033912915088 and parameters: {'learning_rate': 0.023838707372662464, 'n_estimators': 600, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 210}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:03,815] Trial 236 finished with value: 541.9668989142644 and parameters: {'learning_rate': 0.039421274314344334, 'n_estimators': 603, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 182}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:09,629] Trial 237 finished with value: 539.938417237222 and parameters: {'learning_rate': 0.029780296301190928, 'n_estimators': 634, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 51}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:16,267] Trial 238 finished with value: 541.0371476525285 and parameters: {'learning_rate': 0.016701351381606708, 'n_estimators': 586, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 196}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:23,780] Trial 239 finished with value: 540.5434514615371 and parameters: {'learning_rate': 0.022533990202459366, 'n_estimators': 614, 'depth': 10, 'l2_leaf_reg': 3, 'border_count': 203}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:30,119] Trial 240 finished with value: 539.9962629913483 and parameters: {'learning_rate': 0.030545760964522134, 'n_estimators': 554, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 189}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:33,554] Trial 241 finished with value: 540.1168466582325 and parameters: {'learning_rate': 0.03591765721236055, 'n_estimators': 513, 'depth': 9, 'l2_leaf_reg': 7, 'border_count': 177}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:43,869] Trial 242 finished with value: 540.7895870996626 and parameters: {'learning_rate': 0.0271704912357112, 'n_estimators': 805, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 166}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:48,408] Trial 243 finished with value: 541.4039168637078 and parameters: {'learning_rate': 0.01969439369678755, 'n_estimators': 641, 'depth': 9, 'l2_leaf_reg': 10, 'border_count': 171}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:09:53,460] Trial 244 finished with value: 540.8933392410586 and parameters: {'learning_rate': 0.030432526236079057, 'n_estimators': 399, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 180}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:10:02,722] Trial 245 finished with value: 540.0855316052656 and parameters: {'learning_rate': 0.015224964268306818, 'n_estimators': 785, 'depth': 10, 'l2_leaf_reg': 7, 'border_count': 184}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:10:06,896] Trial 246 finished with value: 540.5119529197733 and parameters: {'learning_rate': 0.02564310690744657, 'n_estimators': 569, 'depth': 9, 'l2_leaf_reg': 9, 'border_count': 191}. Best is trial 222 with value: 538.9357725249145.\n",
      "[I 2024-04-03 22:10:18,244] Trial 247 finished with value: 541.4534350031068 and parameters: {'learning_rate': 0.041330647463869205, 'n_estimators': 933, 'depth': 10, 'l2_leaf_reg': 10, 'border_count': 197}. Best is trial 222 with value: 538.9357725249145.\n",
      "[W 2024-04-03 22:10:23,301] Trial 248 failed with parameters: {'learning_rate': 0.036193783299119486, 'n_estimators': 830, 'depth': 10, 'l2_leaf_reg': 9, 'border_count': 176} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SJ\\anaconda3\\envs\\study\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\SJ\\AppData\\Local\\Temp\\ipykernel_1468\\1475100105.py\", line 70, in objective\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\SJ\\anaconda3\\envs\\study\\lib\\site-packages\\catboost\\core.py\", line 5734, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"C:\\Users\\SJ\\anaconda3\\envs\\study\\lib\\site-packages\\catboost\\core.py\", line 2357, in _fit\n",
      "    self._train(\n",
      "  File \"C:\\Users\\SJ\\anaconda3\\envs\\study\\lib\\site-packages\\catboost\\core.py\", line 1761, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4624, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4673, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2024-04-03 22:10:23,374] Trial 248 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[102], line 80\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;66;03m# Optuna 최적화 실행\u001B[39;00m\n\u001B[0;32m     79\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mminimize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 80\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;66;03m# 최적의 파라미터 출력\u001B[39;00m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBest trial: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstudy\u001B[38;5;241m.\u001B[39mbest_trial\u001B[38;5;241m.\u001B[39mparams\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\optuna\\study\\study.py:451\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    349\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    350\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    357\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    358\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    360\u001B[0m \n\u001B[0;32m    361\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 451\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    452\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    455\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    461\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 66\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     79\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[102], line 70\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m     67\u001B[0m     model \u001B[38;5;241m=\u001B[39m CatBoostRegressor(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparam)\n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m# 모델 학습\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[38;5;66;03m# 예측 및 평가\u001B[39;00m\n\u001B[0;32m     73\u001B[0m preds \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_test)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\catboost\\core.py:5734\u001B[0m, in \u001B[0;36mCatBoostRegressor.fit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   5731\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss_function\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[0;32m   5732\u001B[0m     CatBoostRegressor\u001B[38;5;241m.\u001B[39m_check_is_compatible_loss(params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss_function\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m-> 5734\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcat_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbaseline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5735\u001B[0m \u001B[43m                 \u001B[49m\u001B[43muse_best_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogging_level\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplot_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_description\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5736\u001B[0m \u001B[43m                 \u001B[49m\u001B[43mverbose_eval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric_period\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msilent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5737\u001B[0m \u001B[43m                 \u001B[49m\u001B[43msave_snapshot\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msnapshot_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msnapshot_interval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_cout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_cerr\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\catboost\\core.py:2357\u001B[0m, in \u001B[0;36mCatBoost._fit\u001B[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001B[0m\n\u001B[0;32m   2353\u001B[0m allow_clear_pool \u001B[38;5;241m=\u001B[39m train_params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_clear_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   2355\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m log_fixup(log_cout, log_cerr), \\\n\u001B[0;32m   2356\u001B[0m     plot_wrapper(plot, plot_file, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining plots\u001B[39m\u001B[38;5;124m'\u001B[39m, [_get_train_dir(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_params())]):\n\u001B[1;32m-> 2357\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2358\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_pool\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2359\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meval_sets\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2361\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_clear_pool\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2362\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_params\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minit_model\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m   2363\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2365\u001B[0m \u001B[38;5;66;03m# Have property feature_importance possibly set\u001B[39;00m\n\u001B[0;32m   2366\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_object\u001B[38;5;241m.\u001B[39m_get_loss_function_name()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\study\\lib\\site-packages\\catboost\\core.py:1761\u001B[0m, in \u001B[0;36m_CatBoostBase._train\u001B[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001B[0m\n\u001B[0;32m   1760\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_train\u001B[39m(\u001B[38;5;28mself\u001B[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001B[1;32m-> 1761\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_object\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_pool\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_pool\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_clear_pool\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_object\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1762\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_trained_model_attributes()\n",
      "File \u001B[1;32m_catboost.pyx:4624\u001B[0m, in \u001B[0;36m_catboost._CatBoost._train\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_catboost.pyx:4673\u001B[0m, in \u001B[0;36m_catboost._CatBoost._train\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def objective(trial):\n",
    "    # 모델 선택\n",
    "    # model_type = trial.suggest_categorical('model_type', ['xgboost', 'lightgbm', 'random_forest', 'gradient_boosting'])\n",
    "    model_type = 'catboost'\n",
    "    # 모델 별 파라미터 설정\n",
    "    if model_type == 'xgboost':\n",
    "        param = {\n",
    "            'objective': 'reg:squarederror',\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 9),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "            # L1 정규화 매개변수 (alpha)\n",
    "            'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
    "            # L2 정규화 매개변수 (lambda)\n",
    "            'lambda': trial.suggest_float('lambda', 1.0, 100.0),\n",
    "        }\n",
    "        model = XGBRegressor(**param)\n",
    "    elif model_type == 'lightgbm':\n",
    "        param = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', -1, 9),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        }\n",
    "        model = LGBMRegressor(**param)\n",
    "    elif model_type == 'random_forest':\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 8),\n",
    "        }\n",
    "        model = RandomForestRegressor(**param)\n",
    "    elif model_type == 'gradient_boosting':\n",
    "        param = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 9),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 8),\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        }\n",
    "        model = GradientBoostingRegressor(**param)\n",
    "\n",
    "    elif model_type == 'catboost':\n",
    "        param = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'depth': trial.suggest_int('depth', 4, 10),\n",
    "            'l2_leaf_reg': trial.suggest_int('l2_leaf_reg', 1, 10),\n",
    "            'border_count': trial.suggest_int('border_count', 1, 255),\n",
    "            'logging_level': 'Silent',\n",
    "        }\n",
    "        model = CatBoostRegressor(**param)\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # 예측 및 평가\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "    return rmse\n",
    "\n",
    "# Optuna 최적화 실행\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=300)\n",
    "\n",
    "# 최적의 파라미터 출력\n",
    "print(f\"Best trial: {study.best_trial.params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:10:24.151977600Z",
     "start_time": "2024-04-03T12:44:51.892690Z"
    }
   },
   "id": "719b3ce4e14571fd"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "#  # 최적의 파라미터로 모델 재학습\n",
    "# best_params = study.best_trial.params\n",
    "# model = XGBRegressor(**best_params)\n",
    "# model.fit(X_train, y_train)\n",
    "# \n",
    "# # 특성 중요도 추출\n",
    "# feature_importances = model.feature_importances_\n",
    "# \n",
    "# # 특성 이름을 가져오기 (X_train이 pandas DataFrame일 경우)\n",
    "# feature_names = X_train.columns\n",
    "# \n",
    "# # 특성 중요도를 DataFrame으로 변환\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'Feature': feature_names,\n",
    "#     'Importance': feature_importances\n",
    "# }).sort_values(by='Importance', ascending=False)\n",
    "# \n",
    "# # 중요도가 높은 순으로 특성 출력\n",
    "# print(importance_df)\n",
    "# \n",
    "# # 특성 중요도 시각화\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "# plt.xlabel('Importance')\n",
    "# plt.ylabel('Feature')\n",
    "# plt.title('Feature Importance')\n",
    "# plt.gca().invert_yaxis()  # 중요도가 높은 특성을 위로\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T11:54:35.890773100Z",
     "start_time": "2024-04-03T11:54:35.132585500Z"
    }
   },
   "id": "7ee4f61ff649d7a2"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB RMSE: 537.2666897761321\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "xgb_model = XGBRegressor(**best_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Best trial: {'learning_rate': 0.02550289892498271, 'n_estimators': 382, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8120163205571489, 'colsample_bytree': 0.6287152249249107}\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "# RMSE 계산\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
    "print(f\"XGB RMSE: {rmse_xgb}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:36:09.748576400Z",
     "start_time": "2024-04-03T12:36:09.411090900Z"
    }
   },
   "id": "2b1845afcc0caca1"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 536\n",
      "[LightGBM] [Info] Number of data points in the train set: 15967, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 552.680904\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "lgbm RMSE: 537.5424544049027\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "lgbm_model = LGBMRegressor(**best_params)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "# RMSE 계산\n",
    "rmse_lgbm = mean_squared_error(y_test, y_pred_lgbm, squared=False)\n",
    "print(f\"lgbm RMSE: {rmse_lgbm}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:44:23.939985100Z",
     "start_time": "2024-04-03T12:44:22.465357700Z"
    }
   },
   "id": "a3adea9b6102183e"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 665.1445419\ttotal: 12.3ms\tremaining: 7.17s\n",
      "1:\tlearn: 658.9514072\ttotal: 22.5ms\tremaining: 6.58s\n",
      "2:\tlearn: 652.8485167\ttotal: 34.1ms\tremaining: 6.62s\n",
      "3:\tlearn: 647.3036989\ttotal: 45ms\tremaining: 6.55s\n",
      "4:\tlearn: 641.9979369\ttotal: 55.6ms\tremaining: 6.46s\n",
      "5:\tlearn: 636.8110203\ttotal: 66.9ms\tremaining: 6.47s\n",
      "6:\tlearn: 632.0203196\ttotal: 79ms\tremaining: 6.54s\n",
      "7:\tlearn: 627.4058268\ttotal: 85.5ms\tremaining: 6.18s\n",
      "8:\tlearn: 623.1013476\ttotal: 96.6ms\tremaining: 6.19s\n",
      "9:\tlearn: 619.0404642\ttotal: 108ms\tremaining: 6.2s\n",
      "10:\tlearn: 615.2483985\ttotal: 118ms\tremaining: 6.17s\n",
      "11:\tlearn: 611.6297735\ttotal: 130ms\tremaining: 6.2s\n",
      "12:\tlearn: 608.1987995\ttotal: 141ms\tremaining: 6.2s\n",
      "13:\tlearn: 604.9297040\ttotal: 151ms\tremaining: 6.18s\n",
      "14:\tlearn: 602.0513434\ttotal: 162ms\tremaining: 6.16s\n",
      "15:\tlearn: 599.2084686\ttotal: 172ms\tremaining: 6.13s\n",
      "16:\tlearn: 596.5381681\ttotal: 183ms\tremaining: 6.12s\n",
      "17:\tlearn: 594.1022426\ttotal: 193ms\tremaining: 6.09s\n",
      "18:\tlearn: 591.7430593\ttotal: 203ms\tremaining: 6.06s\n",
      "19:\tlearn: 589.4713659\ttotal: 213ms\tremaining: 6.04s\n",
      "20:\tlearn: 587.2440494\ttotal: 224ms\tremaining: 6.03s\n",
      "21:\tlearn: 585.1482390\ttotal: 234ms\tremaining: 6.01s\n",
      "22:\tlearn: 583.2365186\ttotal: 245ms\tremaining: 6s\n",
      "23:\tlearn: 581.2988351\ttotal: 256ms\tremaining: 5.98s\n",
      "24:\tlearn: 579.6584423\ttotal: 266ms\tremaining: 5.98s\n",
      "25:\tlearn: 578.0019599\ttotal: 277ms\tremaining: 5.98s\n",
      "26:\tlearn: 576.5458308\ttotal: 289ms\tremaining: 5.98s\n",
      "27:\tlearn: 575.1663026\ttotal: 299ms\tremaining: 5.95s\n",
      "28:\tlearn: 573.8720644\ttotal: 309ms\tremaining: 5.92s\n",
      "29:\tlearn: 572.4372193\ttotal: 319ms\tremaining: 5.91s\n",
      "30:\tlearn: 571.1472063\ttotal: 329ms\tremaining: 5.89s\n",
      "31:\tlearn: 570.0162026\ttotal: 339ms\tremaining: 5.87s\n",
      "32:\tlearn: 568.8527446\ttotal: 349ms\tremaining: 5.84s\n",
      "33:\tlearn: 567.7997931\ttotal: 359ms\tremaining: 5.83s\n",
      "34:\tlearn: 566.7721635\ttotal: 369ms\tremaining: 5.81s\n",
      "35:\tlearn: 565.7585086\ttotal: 380ms\tremaining: 5.8s\n",
      "36:\tlearn: 565.1310901\ttotal: 382ms\tremaining: 5.67s\n",
      "37:\tlearn: 564.1771182\ttotal: 393ms\tremaining: 5.66s\n",
      "38:\tlearn: 563.3782080\ttotal: 403ms\tremaining: 5.65s\n",
      "39:\tlearn: 562.5245388\ttotal: 413ms\tremaining: 5.64s\n",
      "40:\tlearn: 561.9218212\ttotal: 424ms\tremaining: 5.63s\n",
      "41:\tlearn: 561.1880702\ttotal: 435ms\tremaining: 5.63s\n",
      "42:\tlearn: 560.5314465\ttotal: 444ms\tremaining: 5.61s\n",
      "43:\tlearn: 559.8895806\ttotal: 455ms\tremaining: 5.6s\n",
      "44:\tlearn: 559.2317750\ttotal: 466ms\tremaining: 5.6s\n",
      "45:\tlearn: 558.5119171\ttotal: 476ms\tremaining: 5.59s\n",
      "46:\tlearn: 557.8615033\ttotal: 487ms\tremaining: 5.58s\n",
      "47:\tlearn: 557.1203265\ttotal: 496ms\tremaining: 5.56s\n",
      "48:\tlearn: 556.5480537\ttotal: 507ms\tremaining: 5.55s\n",
      "49:\tlearn: 556.2749440\ttotal: 509ms\tremaining: 5.45s\n",
      "50:\tlearn: 555.7900548\ttotal: 518ms\tremaining: 5.44s\n",
      "51:\tlearn: 555.2638811\ttotal: 529ms\tremaining: 5.43s\n",
      "52:\tlearn: 554.7505681\ttotal: 540ms\tremaining: 5.43s\n",
      "53:\tlearn: 554.2624757\ttotal: 550ms\tremaining: 5.42s\n",
      "54:\tlearn: 553.8929238\ttotal: 560ms\tremaining: 5.41s\n",
      "55:\tlearn: 553.4384876\ttotal: 571ms\tremaining: 5.4s\n",
      "56:\tlearn: 553.0400332\ttotal: 580ms\tremaining: 5.39s\n",
      "57:\tlearn: 552.6313459\ttotal: 591ms\tremaining: 5.38s\n",
      "58:\tlearn: 552.3110107\ttotal: 600ms\tremaining: 5.36s\n",
      "59:\tlearn: 551.7874911\ttotal: 611ms\tremaining: 5.36s\n",
      "60:\tlearn: 551.3930761\ttotal: 621ms\tremaining: 5.34s\n",
      "61:\tlearn: 551.0092795\ttotal: 631ms\tremaining: 5.33s\n",
      "62:\tlearn: 550.6575944\ttotal: 641ms\tremaining: 5.33s\n",
      "63:\tlearn: 550.3546469\ttotal: 652ms\tremaining: 5.32s\n",
      "64:\tlearn: 550.0462417\ttotal: 663ms\tremaining: 5.31s\n",
      "65:\tlearn: 549.7136408\ttotal: 673ms\tremaining: 5.3s\n",
      "66:\tlearn: 549.4216083\ttotal: 683ms\tremaining: 5.29s\n",
      "67:\tlearn: 549.1320496\ttotal: 693ms\tremaining: 5.28s\n",
      "68:\tlearn: 548.8108987\ttotal: 704ms\tremaining: 5.27s\n",
      "69:\tlearn: 548.4552358\ttotal: 714ms\tremaining: 5.26s\n",
      "70:\tlearn: 548.0597023\ttotal: 725ms\tremaining: 5.26s\n",
      "71:\tlearn: 547.6656652\ttotal: 736ms\tremaining: 5.25s\n",
      "72:\tlearn: 547.3570952\ttotal: 745ms\tremaining: 5.24s\n",
      "73:\tlearn: 546.9313686\ttotal: 755ms\tremaining: 5.23s\n",
      "74:\tlearn: 546.4994580\ttotal: 766ms\tremaining: 5.22s\n",
      "75:\tlearn: 546.0595480\ttotal: 777ms\tremaining: 5.21s\n",
      "76:\tlearn: 545.7454118\ttotal: 787ms\tremaining: 5.21s\n",
      "77:\tlearn: 545.5055486\ttotal: 798ms\tremaining: 5.2s\n",
      "78:\tlearn: 545.1535694\ttotal: 809ms\tremaining: 5.19s\n",
      "79:\tlearn: 544.8859539\ttotal: 819ms\tremaining: 5.18s\n",
      "80:\tlearn: 544.6619923\ttotal: 829ms\tremaining: 5.17s\n",
      "81:\tlearn: 544.4145498\ttotal: 839ms\tremaining: 5.16s\n",
      "82:\tlearn: 544.1145288\ttotal: 849ms\tremaining: 5.15s\n",
      "83:\tlearn: 543.8735494\ttotal: 859ms\tremaining: 5.13s\n",
      "84:\tlearn: 543.6912255\ttotal: 869ms\tremaining: 5.12s\n",
      "85:\tlearn: 543.4176848\ttotal: 880ms\tremaining: 5.11s\n",
      "86:\tlearn: 543.1824770\ttotal: 891ms\tremaining: 5.11s\n",
      "87:\tlearn: 542.8448190\ttotal: 902ms\tremaining: 5.1s\n",
      "88:\tlearn: 542.6362119\ttotal: 912ms\tremaining: 5.09s\n",
      "89:\tlearn: 542.4961779\ttotal: 922ms\tremaining: 5.08s\n",
      "90:\tlearn: 542.3219889\ttotal: 933ms\tremaining: 5.08s\n",
      "91:\tlearn: 542.1212898\ttotal: 943ms\tremaining: 5.07s\n",
      "92:\tlearn: 541.8288431\ttotal: 954ms\tremaining: 5.06s\n",
      "93:\tlearn: 541.5136465\ttotal: 964ms\tremaining: 5.05s\n",
      "94:\tlearn: 541.3198152\ttotal: 975ms\tremaining: 5.04s\n",
      "95:\tlearn: 541.0115982\ttotal: 986ms\tremaining: 5.03s\n",
      "96:\tlearn: 540.8374123\ttotal: 998ms\tremaining: 5.03s\n",
      "97:\tlearn: 540.6052852\ttotal: 1.01s\tremaining: 5.02s\n",
      "98:\tlearn: 540.2782976\ttotal: 1.02s\tremaining: 5.02s\n",
      "99:\tlearn: 540.1340399\ttotal: 1.03s\tremaining: 5.01s\n",
      "100:\tlearn: 539.8070837\ttotal: 1.04s\tremaining: 5s\n",
      "101:\tlearn: 539.6365541\ttotal: 1.05s\tremaining: 5s\n",
      "102:\tlearn: 539.4622526\ttotal: 1.06s\tremaining: 4.99s\n",
      "103:\tlearn: 539.2666841\ttotal: 1.07s\tremaining: 4.98s\n",
      "104:\tlearn: 539.1037755\ttotal: 1.08s\tremaining: 4.97s\n",
      "105:\tlearn: 538.8489290\ttotal: 1.1s\tremaining: 4.97s\n",
      "106:\tlearn: 538.6413636\ttotal: 1.11s\tremaining: 4.96s\n",
      "107:\tlearn: 538.4275764\ttotal: 1.12s\tremaining: 4.95s\n",
      "108:\tlearn: 538.1764889\ttotal: 1.13s\tremaining: 4.94s\n",
      "109:\tlearn: 538.0271542\ttotal: 1.14s\tremaining: 4.92s\n",
      "110:\tlearn: 537.9960269\ttotal: 1.14s\tremaining: 4.88s\n",
      "111:\tlearn: 537.7809262\ttotal: 1.15s\tremaining: 4.87s\n",
      "112:\tlearn: 537.5407630\ttotal: 1.16s\tremaining: 4.86s\n",
      "113:\tlearn: 537.3421182\ttotal: 1.17s\tremaining: 4.85s\n",
      "114:\tlearn: 537.1746175\ttotal: 1.18s\tremaining: 4.83s\n",
      "115:\tlearn: 537.0273043\ttotal: 1.19s\tremaining: 4.82s\n",
      "116:\tlearn: 536.8406418\ttotal: 1.2s\tremaining: 4.81s\n",
      "117:\tlearn: 536.7700155\ttotal: 1.21s\tremaining: 4.81s\n",
      "118:\tlearn: 536.6496130\ttotal: 1.22s\tremaining: 4.79s\n",
      "119:\tlearn: 536.5476024\ttotal: 1.23s\tremaining: 4.76s\n",
      "120:\tlearn: 536.3098033\ttotal: 1.24s\tremaining: 4.75s\n",
      "121:\tlearn: 536.1832642\ttotal: 1.25s\tremaining: 4.74s\n",
      "122:\tlearn: 535.9850876\ttotal: 1.26s\tremaining: 4.73s\n",
      "123:\tlearn: 535.7400244\ttotal: 1.27s\tremaining: 4.72s\n",
      "124:\tlearn: 535.5595062\ttotal: 1.28s\tremaining: 4.72s\n",
      "125:\tlearn: 535.4298938\ttotal: 1.29s\tremaining: 4.71s\n",
      "126:\tlearn: 535.2829367\ttotal: 1.3s\tremaining: 4.7s\n",
      "127:\tlearn: 535.1301326\ttotal: 1.31s\tremaining: 4.69s\n",
      "128:\tlearn: 535.0084965\ttotal: 1.32s\tremaining: 4.68s\n",
      "129:\tlearn: 534.8462642\ttotal: 1.33s\tremaining: 4.67s\n",
      "130:\tlearn: 534.6973035\ttotal: 1.34s\tremaining: 4.66s\n",
      "131:\tlearn: 534.4802773\ttotal: 1.35s\tremaining: 4.65s\n",
      "132:\tlearn: 534.3250069\ttotal: 1.36s\tremaining: 4.64s\n",
      "133:\tlearn: 534.1778554\ttotal: 1.37s\tremaining: 4.63s\n",
      "134:\tlearn: 534.0404973\ttotal: 1.38s\tremaining: 4.62s\n",
      "135:\tlearn: 533.7653416\ttotal: 1.39s\tremaining: 4.61s\n",
      "136:\tlearn: 533.6489310\ttotal: 1.4s\tremaining: 4.6s\n",
      "137:\tlearn: 533.4752970\ttotal: 1.41s\tremaining: 4.59s\n",
      "138:\tlearn: 533.2034484\ttotal: 1.42s\tremaining: 4.58s\n",
      "139:\tlearn: 532.9497914\ttotal: 1.44s\tremaining: 4.57s\n",
      "140:\tlearn: 532.8164611\ttotal: 1.45s\tremaining: 4.56s\n",
      "141:\tlearn: 532.6861918\ttotal: 1.46s\tremaining: 4.55s\n",
      "142:\tlearn: 532.6209073\ttotal: 1.47s\tremaining: 4.55s\n",
      "143:\tlearn: 532.4221522\ttotal: 1.48s\tremaining: 4.54s\n",
      "144:\tlearn: 532.2476249\ttotal: 1.49s\tremaining: 4.53s\n",
      "145:\tlearn: 531.9057307\ttotal: 1.5s\tremaining: 4.52s\n",
      "146:\tlearn: 531.7838273\ttotal: 1.51s\tremaining: 4.51s\n",
      "147:\tlearn: 531.6863250\ttotal: 1.52s\tremaining: 4.5s\n",
      "148:\tlearn: 531.6186522\ttotal: 1.53s\tremaining: 4.5s\n",
      "149:\tlearn: 531.4298853\ttotal: 1.54s\tremaining: 4.49s\n",
      "150:\tlearn: 531.2125749\ttotal: 1.55s\tremaining: 4.47s\n",
      "151:\tlearn: 530.9583337\ttotal: 1.56s\tremaining: 4.46s\n",
      "152:\tlearn: 530.6184682\ttotal: 1.57s\tremaining: 4.45s\n",
      "153:\tlearn: 530.5311234\ttotal: 1.58s\tremaining: 4.45s\n",
      "154:\tlearn: 530.3894883\ttotal: 1.59s\tremaining: 4.43s\n",
      "155:\tlearn: 530.2685631\ttotal: 1.6s\tremaining: 4.43s\n",
      "156:\tlearn: 530.1447043\ttotal: 1.62s\tremaining: 4.42s\n",
      "157:\tlearn: 529.9577497\ttotal: 1.63s\tremaining: 4.41s\n",
      "158:\tlearn: 529.7804278\ttotal: 1.64s\tremaining: 4.4s\n",
      "159:\tlearn: 529.6201462\ttotal: 1.65s\tremaining: 4.39s\n",
      "160:\tlearn: 529.4965781\ttotal: 1.66s\tremaining: 4.37s\n",
      "161:\tlearn: 529.3550215\ttotal: 1.67s\tremaining: 4.37s\n",
      "162:\tlearn: 529.2416098\ttotal: 1.68s\tremaining: 4.35s\n",
      "163:\tlearn: 529.1379532\ttotal: 1.69s\tremaining: 4.35s\n",
      "164:\tlearn: 528.9966937\ttotal: 1.7s\tremaining: 4.34s\n",
      "165:\tlearn: 528.8661386\ttotal: 1.71s\tremaining: 4.33s\n",
      "166:\tlearn: 528.8177953\ttotal: 1.72s\tremaining: 4.32s\n",
      "167:\tlearn: 528.6647814\ttotal: 1.73s\tremaining: 4.32s\n",
      "168:\tlearn: 528.5620767\ttotal: 1.74s\tremaining: 4.3s\n",
      "169:\tlearn: 528.4947776\ttotal: 1.75s\tremaining: 4.3s\n",
      "170:\tlearn: 528.3613081\ttotal: 1.76s\tremaining: 4.28s\n",
      "171:\tlearn: 528.2341830\ttotal: 1.77s\tremaining: 4.27s\n",
      "172:\tlearn: 528.1383340\ttotal: 1.78s\tremaining: 4.26s\n",
      "173:\tlearn: 527.9773101\ttotal: 1.8s\tremaining: 4.25s\n",
      "174:\tlearn: 527.9115731\ttotal: 1.81s\tremaining: 4.24s\n",
      "175:\tlearn: 527.8467903\ttotal: 1.82s\tremaining: 4.23s\n",
      "176:\tlearn: 527.6957428\ttotal: 1.83s\tremaining: 4.22s\n",
      "177:\tlearn: 527.6134277\ttotal: 1.84s\tremaining: 4.21s\n",
      "178:\tlearn: 527.5742838\ttotal: 1.85s\tremaining: 4.2s\n",
      "179:\tlearn: 527.5081918\ttotal: 1.86s\tremaining: 4.19s\n",
      "180:\tlearn: 527.3289067\ttotal: 1.87s\tremaining: 4.17s\n",
      "181:\tlearn: 527.1607649\ttotal: 1.88s\tremaining: 4.17s\n",
      "182:\tlearn: 527.0723482\ttotal: 1.89s\tremaining: 4.16s\n",
      "183:\tlearn: 527.0606440\ttotal: 1.9s\tremaining: 4.14s\n",
      "184:\tlearn: 526.9725649\ttotal: 1.91s\tremaining: 4.13s\n",
      "185:\tlearn: 526.8319543\ttotal: 1.92s\tremaining: 4.13s\n",
      "186:\tlearn: 526.6987460\ttotal: 1.93s\tremaining: 4.12s\n",
      "187:\tlearn: 526.5727529\ttotal: 1.94s\tremaining: 4.11s\n",
      "188:\tlearn: 526.4233977\ttotal: 1.95s\tremaining: 4.09s\n",
      "189:\tlearn: 526.3441887\ttotal: 1.96s\tremaining: 4.08s\n",
      "190:\tlearn: 526.2056643\ttotal: 1.97s\tremaining: 4.07s\n",
      "191:\tlearn: 526.1110206\ttotal: 1.98s\tremaining: 4.06s\n",
      "192:\tlearn: 525.9686826\ttotal: 1.99s\tremaining: 4.05s\n",
      "193:\tlearn: 525.8730699\ttotal: 2s\tremaining: 4.04s\n",
      "194:\tlearn: 525.6584009\ttotal: 2.01s\tremaining: 4.03s\n",
      "195:\tlearn: 525.5351900\ttotal: 2.02s\tremaining: 4.02s\n",
      "196:\tlearn: 525.5058767\ttotal: 2.02s\tremaining: 4s\n",
      "197:\tlearn: 525.2941753\ttotal: 2.04s\tremaining: 3.99s\n",
      "198:\tlearn: 525.2036792\ttotal: 2.04s\tremaining: 3.98s\n",
      "199:\tlearn: 525.1010290\ttotal: 2.06s\tremaining: 3.97s\n",
      "200:\tlearn: 525.0135097\ttotal: 2.06s\tremaining: 3.96s\n",
      "201:\tlearn: 524.7033715\ttotal: 2.08s\tremaining: 3.94s\n",
      "202:\tlearn: 524.6468510\ttotal: 2.08s\tremaining: 3.94s\n",
      "203:\tlearn: 524.5819784\ttotal: 2.1s\tremaining: 3.93s\n",
      "204:\tlearn: 524.4883913\ttotal: 2.11s\tremaining: 3.92s\n",
      "205:\tlearn: 524.4406308\ttotal: 2.12s\tremaining: 3.9s\n",
      "206:\tlearn: 524.2869081\ttotal: 2.13s\tremaining: 3.9s\n",
      "207:\tlearn: 524.1984016\ttotal: 2.14s\tremaining: 3.89s\n",
      "208:\tlearn: 524.0560274\ttotal: 2.15s\tremaining: 3.88s\n",
      "209:\tlearn: 523.9098844\ttotal: 2.16s\tremaining: 3.87s\n",
      "210:\tlearn: 523.8330571\ttotal: 2.17s\tremaining: 3.85s\n",
      "211:\tlearn: 523.7156414\ttotal: 2.18s\tremaining: 3.84s\n",
      "212:\tlearn: 523.6269451\ttotal: 2.19s\tremaining: 3.83s\n",
      "213:\tlearn: 523.4769446\ttotal: 2.2s\tremaining: 3.82s\n",
      "214:\tlearn: 523.4235904\ttotal: 2.21s\tremaining: 3.81s\n",
      "215:\tlearn: 523.3251207\ttotal: 2.22s\tremaining: 3.8s\n",
      "216:\tlearn: 523.2225991\ttotal: 2.23s\tremaining: 3.79s\n",
      "217:\tlearn: 523.0343563\ttotal: 2.24s\tremaining: 3.78s\n",
      "218:\tlearn: 522.8847043\ttotal: 2.25s\tremaining: 3.77s\n",
      "219:\tlearn: 522.8472128\ttotal: 2.26s\tremaining: 3.76s\n",
      "220:\tlearn: 522.7819309\ttotal: 2.27s\tremaining: 3.75s\n",
      "221:\tlearn: 522.5222584\ttotal: 2.28s\tremaining: 3.73s\n",
      "222:\tlearn: 522.4778023\ttotal: 2.29s\tremaining: 3.72s\n",
      "223:\tlearn: 522.3333271\ttotal: 2.3s\tremaining: 3.71s\n",
      "224:\tlearn: 522.1134824\ttotal: 2.31s\tremaining: 3.7s\n",
      "225:\tlearn: 522.1016515\ttotal: 2.31s\tremaining: 3.68s\n",
      "226:\tlearn: 522.0530539\ttotal: 2.32s\tremaining: 3.67s\n",
      "227:\tlearn: 522.0131767\ttotal: 2.33s\tremaining: 3.66s\n",
      "228:\tlearn: 521.8410649\ttotal: 2.34s\tremaining: 3.65s\n",
      "229:\tlearn: 521.7661435\ttotal: 2.35s\tremaining: 3.65s\n",
      "230:\tlearn: 521.6671989\ttotal: 2.37s\tremaining: 3.64s\n",
      "231:\tlearn: 521.5951262\ttotal: 2.38s\tremaining: 3.63s\n",
      "232:\tlearn: 521.5719887\ttotal: 2.38s\tremaining: 3.6s\n",
      "233:\tlearn: 521.4972554\ttotal: 2.39s\tremaining: 3.59s\n",
      "234:\tlearn: 521.3811940\ttotal: 2.4s\tremaining: 3.58s\n",
      "235:\tlearn: 521.1982806\ttotal: 2.41s\tremaining: 3.57s\n",
      "236:\tlearn: 521.0135570\ttotal: 2.42s\tremaining: 3.56s\n",
      "237:\tlearn: 520.8817443\ttotal: 2.43s\tremaining: 3.55s\n",
      "238:\tlearn: 520.7922422\ttotal: 2.44s\tremaining: 3.54s\n",
      "239:\tlearn: 520.6748124\ttotal: 2.45s\tremaining: 3.53s\n",
      "240:\tlearn: 520.6083764\ttotal: 2.46s\tremaining: 3.52s\n",
      "241:\tlearn: 520.4435382\ttotal: 2.47s\tremaining: 3.51s\n",
      "242:\tlearn: 520.3676105\ttotal: 2.48s\tremaining: 3.5s\n",
      "243:\tlearn: 520.1628628\ttotal: 2.49s\tremaining: 3.5s\n",
      "244:\tlearn: 520.0819534\ttotal: 2.5s\tremaining: 3.48s\n",
      "245:\tlearn: 519.8621423\ttotal: 2.51s\tremaining: 3.47s\n",
      "246:\tlearn: 519.8278611\ttotal: 2.52s\tremaining: 3.46s\n",
      "247:\tlearn: 519.7844321\ttotal: 2.53s\tremaining: 3.45s\n",
      "248:\tlearn: 519.6369859\ttotal: 2.54s\tremaining: 3.44s\n",
      "249:\tlearn: 519.5363389\ttotal: 2.55s\tremaining: 3.43s\n",
      "250:\tlearn: 519.4326020\ttotal: 2.56s\tremaining: 3.42s\n",
      "251:\tlearn: 519.3472522\ttotal: 2.57s\tremaining: 3.41s\n",
      "252:\tlearn: 519.2581511\ttotal: 2.58s\tremaining: 3.4s\n",
      "253:\tlearn: 518.9525828\ttotal: 2.6s\tremaining: 3.39s\n",
      "254:\tlearn: 518.7850366\ttotal: 2.6s\tremaining: 3.38s\n",
      "255:\tlearn: 518.6712086\ttotal: 2.62s\tremaining: 3.37s\n",
      "256:\tlearn: 518.5168659\ttotal: 2.63s\tremaining: 3.36s\n",
      "257:\tlearn: 518.4559178\ttotal: 2.63s\tremaining: 3.35s\n",
      "258:\tlearn: 518.3877329\ttotal: 2.65s\tremaining: 3.34s\n",
      "259:\tlearn: 518.3420007\ttotal: 2.65s\tremaining: 3.33s\n",
      "260:\tlearn: 518.2280073\ttotal: 2.67s\tremaining: 3.32s\n",
      "261:\tlearn: 518.1694851\ttotal: 2.67s\tremaining: 3.31s\n",
      "262:\tlearn: 518.1292366\ttotal: 2.69s\tremaining: 3.3s\n",
      "263:\tlearn: 517.8659031\ttotal: 2.7s\tremaining: 3.29s\n",
      "264:\tlearn: 517.6149163\ttotal: 2.71s\tremaining: 3.28s\n",
      "265:\tlearn: 517.5033408\ttotal: 2.72s\tremaining: 3.27s\n",
      "266:\tlearn: 517.3639939\ttotal: 2.73s\tremaining: 3.26s\n",
      "267:\tlearn: 517.2377186\ttotal: 2.74s\tremaining: 3.25s\n",
      "268:\tlearn: 517.2282377\ttotal: 2.74s\tremaining: 3.23s\n",
      "269:\tlearn: 517.1127833\ttotal: 2.75s\tremaining: 3.22s\n",
      "270:\tlearn: 516.9840172\ttotal: 2.76s\tremaining: 3.21s\n",
      "271:\tlearn: 516.7402788\ttotal: 2.77s\tremaining: 3.2s\n",
      "272:\tlearn: 516.4868446\ttotal: 2.78s\tremaining: 3.19s\n",
      "273:\tlearn: 516.4209809\ttotal: 2.79s\tremaining: 3.18s\n",
      "274:\tlearn: 516.2506467\ttotal: 2.8s\tremaining: 3.17s\n",
      "275:\tlearn: 516.2056099\ttotal: 2.81s\tremaining: 3.16s\n",
      "276:\tlearn: 516.1902935\ttotal: 2.81s\tremaining: 3.14s\n",
      "277:\tlearn: 516.1626361\ttotal: 2.82s\tremaining: 3.12s\n",
      "278:\tlearn: 516.1273185\ttotal: 2.83s\tremaining: 3.11s\n",
      "279:\tlearn: 516.0882587\ttotal: 2.83s\tremaining: 3.09s\n",
      "280:\tlearn: 516.0616918\ttotal: 2.84s\tremaining: 3.08s\n",
      "281:\tlearn: 515.9571070\ttotal: 2.85s\tremaining: 3.07s\n",
      "282:\tlearn: 515.7632821\ttotal: 2.86s\tremaining: 3.06s\n",
      "283:\tlearn: 515.7291217\ttotal: 2.86s\tremaining: 3.05s\n",
      "284:\tlearn: 515.7134618\ttotal: 2.87s\tremaining: 3.03s\n",
      "285:\tlearn: 515.5863496\ttotal: 2.88s\tremaining: 3.02s\n",
      "286:\tlearn: 515.5451552\ttotal: 2.89s\tremaining: 3.01s\n",
      "287:\tlearn: 515.5246028\ttotal: 2.89s\tremaining: 2.99s\n",
      "288:\tlearn: 515.3079022\ttotal: 2.9s\tremaining: 2.98s\n",
      "289:\tlearn: 515.2867506\ttotal: 2.91s\tremaining: 2.97s\n",
      "290:\tlearn: 515.2394116\ttotal: 2.92s\tremaining: 2.96s\n",
      "291:\tlearn: 515.1695751\ttotal: 2.94s\tremaining: 2.96s\n",
      "292:\tlearn: 515.0519387\ttotal: 2.95s\tremaining: 2.95s\n",
      "293:\tlearn: 515.0291631\ttotal: 2.96s\tremaining: 2.94s\n",
      "294:\tlearn: 514.9355785\ttotal: 2.97s\tremaining: 2.92s\n",
      "295:\tlearn: 514.8084473\ttotal: 2.98s\tremaining: 2.92s\n",
      "296:\tlearn: 514.6708472\ttotal: 2.99s\tremaining: 2.91s\n",
      "297:\tlearn: 514.5387777\ttotal: 3s\tremaining: 2.9s\n",
      "298:\tlearn: 514.5031632\ttotal: 3s\tremaining: 2.88s\n",
      "299:\tlearn: 514.3844199\ttotal: 3.02s\tremaining: 2.87s\n",
      "300:\tlearn: 514.2967599\ttotal: 3.02s\tremaining: 2.86s\n",
      "301:\tlearn: 514.2620417\ttotal: 3.03s\tremaining: 2.85s\n",
      "302:\tlearn: 514.2271888\ttotal: 3.04s\tremaining: 2.84s\n",
      "303:\tlearn: 514.1942559\ttotal: 3.05s\tremaining: 2.83s\n",
      "304:\tlearn: 514.1387688\ttotal: 3.06s\tremaining: 2.82s\n",
      "305:\tlearn: 514.0998313\ttotal: 3.07s\tremaining: 2.81s\n",
      "306:\tlearn: 513.9302482\ttotal: 3.08s\tremaining: 2.8s\n",
      "307:\tlearn: 513.7313997\ttotal: 3.09s\tremaining: 2.79s\n",
      "308:\tlearn: 513.7178808\ttotal: 3.1s\tremaining: 2.78s\n",
      "309:\tlearn: 513.7044472\ttotal: 3.11s\tremaining: 2.77s\n",
      "310:\tlearn: 513.6263236\ttotal: 3.12s\tremaining: 2.76s\n",
      "311:\tlearn: 513.6126241\ttotal: 3.12s\tremaining: 2.74s\n",
      "312:\tlearn: 513.5239347\ttotal: 3.13s\tremaining: 2.73s\n",
      "313:\tlearn: 513.4406547\ttotal: 3.14s\tremaining: 2.72s\n",
      "314:\tlearn: 513.4236575\ttotal: 3.14s\tremaining: 2.7s\n",
      "315:\tlearn: 513.2510695\ttotal: 3.15s\tremaining: 2.69s\n",
      "316:\tlearn: 513.0254213\ttotal: 3.16s\tremaining: 2.69s\n",
      "317:\tlearn: 512.9523111\ttotal: 3.17s\tremaining: 2.67s\n",
      "318:\tlearn: 512.8569303\ttotal: 3.18s\tremaining: 2.67s\n",
      "319:\tlearn: 512.7197559\ttotal: 3.19s\tremaining: 2.65s\n",
      "320:\tlearn: 512.6510586\ttotal: 3.21s\tremaining: 2.65s\n",
      "321:\tlearn: 512.5215489\ttotal: 3.21s\tremaining: 2.63s\n",
      "322:\tlearn: 512.4854435\ttotal: 3.23s\tremaining: 2.63s\n",
      "323:\tlearn: 512.3924429\ttotal: 3.23s\tremaining: 2.62s\n",
      "324:\tlearn: 512.2492701\ttotal: 3.25s\tremaining: 2.61s\n",
      "325:\tlearn: 512.2368103\ttotal: 3.25s\tremaining: 2.59s\n",
      "326:\tlearn: 512.0496858\ttotal: 3.26s\tremaining: 2.58s\n",
      "327:\tlearn: 512.0144872\ttotal: 3.27s\tremaining: 2.57s\n",
      "328:\tlearn: 512.0022900\ttotal: 3.27s\tremaining: 2.56s\n",
      "329:\tlearn: 511.9674489\ttotal: 3.28s\tremaining: 2.54s\n",
      "330:\tlearn: 511.8007374\ttotal: 3.29s\tremaining: 2.54s\n",
      "331:\tlearn: 511.7457350\ttotal: 3.3s\tremaining: 2.52s\n",
      "332:\tlearn: 511.6721834\ttotal: 3.31s\tremaining: 2.52s\n",
      "333:\tlearn: 511.6383015\ttotal: 3.32s\tremaining: 2.5s\n",
      "334:\tlearn: 511.6198487\ttotal: 3.33s\tremaining: 2.49s\n",
      "335:\tlearn: 511.5485194\ttotal: 3.33s\tremaining: 2.48s\n",
      "336:\tlearn: 511.5119513\ttotal: 3.35s\tremaining: 2.47s\n",
      "337:\tlearn: 511.3868242\ttotal: 3.36s\tremaining: 2.46s\n",
      "338:\tlearn: 511.3538322\ttotal: 3.37s\tremaining: 2.45s\n",
      "339:\tlearn: 511.1354580\ttotal: 3.38s\tremaining: 2.44s\n",
      "340:\tlearn: 511.0125653\ttotal: 3.39s\tremaining: 2.43s\n",
      "341:\tlearn: 510.8708339\ttotal: 3.4s\tremaining: 2.42s\n",
      "342:\tlearn: 510.7869364\ttotal: 3.41s\tremaining: 2.41s\n",
      "343:\tlearn: 510.7425938\ttotal: 3.42s\tremaining: 2.4s\n",
      "344:\tlearn: 510.5794486\ttotal: 3.43s\tremaining: 2.4s\n",
      "345:\tlearn: 510.4208173\ttotal: 3.44s\tremaining: 2.38s\n",
      "346:\tlearn: 510.3873909\ttotal: 3.45s\tremaining: 2.38s\n",
      "347:\tlearn: 510.1666819\ttotal: 3.46s\tremaining: 2.37s\n",
      "348:\tlearn: 510.0556091\ttotal: 3.47s\tremaining: 2.36s\n",
      "349:\tlearn: 509.8527140\ttotal: 3.48s\tremaining: 2.35s\n",
      "350:\tlearn: 509.8209324\ttotal: 3.49s\tremaining: 2.34s\n",
      "351:\tlearn: 509.7096729\ttotal: 3.5s\tremaining: 2.33s\n",
      "352:\tlearn: 509.6774788\ttotal: 3.51s\tremaining: 2.32s\n",
      "353:\tlearn: 509.5461260\ttotal: 3.52s\tremaining: 2.31s\n",
      "354:\tlearn: 509.4511886\ttotal: 3.53s\tremaining: 2.3s\n",
      "355:\tlearn: 509.4199504\ttotal: 3.54s\tremaining: 2.29s\n",
      "356:\tlearn: 509.3890840\ttotal: 3.55s\tremaining: 2.28s\n",
      "357:\tlearn: 509.3058960\ttotal: 3.56s\tremaining: 2.27s\n",
      "358:\tlearn: 509.0575422\ttotal: 3.57s\tremaining: 2.26s\n",
      "359:\tlearn: 508.8287778\ttotal: 3.59s\tremaining: 2.25s\n",
      "360:\tlearn: 508.8176954\ttotal: 3.59s\tremaining: 2.24s\n",
      "361:\tlearn: 508.7848386\ttotal: 3.6s\tremaining: 2.23s\n",
      "362:\tlearn: 508.7545297\ttotal: 3.61s\tremaining: 2.22s\n",
      "363:\tlearn: 508.6883767\ttotal: 3.63s\tremaining: 2.21s\n",
      "364:\tlearn: 508.6562428\ttotal: 3.64s\tremaining: 2.2s\n",
      "365:\tlearn: 508.6268371\ttotal: 3.65s\tremaining: 2.19s\n",
      "366:\tlearn: 508.5976388\ttotal: 3.66s\tremaining: 2.19s\n",
      "367:\tlearn: 508.3709229\ttotal: 3.67s\tremaining: 2.18s\n",
      "368:\tlearn: 508.2338277\ttotal: 3.68s\tremaining: 2.17s\n",
      "369:\tlearn: 508.1057988\ttotal: 3.69s\tremaining: 2.16s\n",
      "370:\tlearn: 508.0770594\ttotal: 3.71s\tremaining: 2.15s\n",
      "371:\tlearn: 508.0481695\ttotal: 3.72s\tremaining: 2.14s\n",
      "372:\tlearn: 508.0199187\ttotal: 3.73s\tremaining: 2.13s\n",
      "373:\tlearn: 507.9314168\ttotal: 3.74s\tremaining: 2.12s\n",
      "374:\tlearn: 507.7083697\ttotal: 3.75s\tremaining: 2.11s\n",
      "375:\tlearn: 507.6778151\ttotal: 3.76s\tremaining: 2.1s\n",
      "376:\tlearn: 507.5044481\ttotal: 3.77s\tremaining: 2.09s\n",
      "377:\tlearn: 507.3172745\ttotal: 3.79s\tremaining: 2.08s\n",
      "378:\tlearn: 507.2403534\ttotal: 3.8s\tremaining: 2.07s\n",
      "379:\tlearn: 507.2128391\ttotal: 3.81s\tremaining: 2.07s\n",
      "380:\tlearn: 507.1845880\ttotal: 3.83s\tremaining: 2.06s\n",
      "381:\tlearn: 507.1574381\ttotal: 3.84s\tremaining: 2.05s\n",
      "382:\tlearn: 507.0389635\ttotal: 3.85s\tremaining: 2.04s\n",
      "383:\tlearn: 507.0119729\ttotal: 3.87s\tremaining: 2.03s\n",
      "384:\tlearn: 506.9852780\ttotal: 3.88s\tremaining: 2.02s\n",
      "385:\tlearn: 506.8518471\ttotal: 3.89s\tremaining: 2.01s\n",
      "386:\tlearn: 506.7917294\ttotal: 3.9s\tremaining: 2s\n",
      "387:\tlearn: 506.7653695\ttotal: 3.91s\tremaining: 1.99s\n",
      "388:\tlearn: 506.7391094\ttotal: 3.92s\tremaining: 1.99s\n",
      "389:\tlearn: 506.6439867\ttotal: 3.93s\tremaining: 1.98s\n",
      "390:\tlearn: 506.6153829\ttotal: 3.94s\tremaining: 1.97s\n",
      "391:\tlearn: 506.5509175\ttotal: 3.95s\tremaining: 1.96s\n",
      "392:\tlearn: 506.4635602\ttotal: 3.96s\tremaining: 1.95s\n",
      "393:\tlearn: 506.3102363\ttotal: 3.98s\tremaining: 1.94s\n",
      "394:\tlearn: 506.2845068\ttotal: 3.99s\tremaining: 1.93s\n",
      "395:\tlearn: 506.2581097\ttotal: 4s\tremaining: 1.92s\n",
      "396:\tlearn: 506.2327734\ttotal: 4.01s\tremaining: 1.91s\n",
      "397:\tlearn: 506.2067995\ttotal: 4.02s\tremaining: 1.9s\n",
      "398:\tlearn: 506.1209453\ttotal: 4.04s\tremaining: 1.89s\n",
      "399:\tlearn: 506.0712534\ttotal: 4.05s\tremaining: 1.88s\n",
      "400:\tlearn: 505.9889129\ttotal: 4.06s\tremaining: 1.87s\n",
      "401:\tlearn: 505.9256103\ttotal: 4.07s\tremaining: 1.86s\n",
      "402:\tlearn: 505.6699155\ttotal: 4.08s\tremaining: 1.85s\n",
      "403:\tlearn: 505.5898709\ttotal: 4.09s\tremaining: 1.84s\n",
      "404:\tlearn: 505.4964910\ttotal: 4.1s\tremaining: 1.83s\n",
      "405:\tlearn: 505.2685551\ttotal: 4.11s\tremaining: 1.82s\n",
      "406:\tlearn: 505.2439994\ttotal: 4.12s\tremaining: 1.81s\n",
      "407:\tlearn: 505.1665325\ttotal: 4.13s\tremaining: 1.8s\n",
      "408:\tlearn: 505.1404489\ttotal: 4.14s\tremaining: 1.79s\n",
      "409:\tlearn: 504.9204388\ttotal: 4.15s\tremaining: 1.78s\n",
      "410:\tlearn: 504.7937417\ttotal: 4.16s\tremaining: 1.77s\n",
      "411:\tlearn: 504.7696780\ttotal: 4.17s\tremaining: 1.76s\n",
      "412:\tlearn: 504.6454283\ttotal: 4.18s\tremaining: 1.75s\n",
      "413:\tlearn: 504.3867641\ttotal: 4.19s\tremaining: 1.74s\n",
      "414:\tlearn: 504.2640489\ttotal: 4.2s\tremaining: 1.73s\n",
      "415:\tlearn: 504.2403175\ttotal: 4.21s\tremaining: 1.72s\n",
      "416:\tlearn: 504.1517150\ttotal: 4.22s\tremaining: 1.71s\n",
      "417:\tlearn: 503.9743001\ttotal: 4.24s\tremaining: 1.7s\n",
      "418:\tlearn: 503.9508956\ttotal: 4.25s\tremaining: 1.69s\n",
      "419:\tlearn: 503.8356831\ttotal: 4.26s\tremaining: 1.68s\n",
      "420:\tlearn: 503.8125297\ttotal: 4.27s\tremaining: 1.67s\n",
      "421:\tlearn: 503.7007344\ttotal: 4.28s\tremaining: 1.66s\n",
      "422:\tlearn: 503.5731406\ttotal: 4.29s\tremaining: 1.65s\n",
      "423:\tlearn: 503.4834251\ttotal: 4.3s\tremaining: 1.64s\n",
      "424:\tlearn: 503.3871366\ttotal: 4.31s\tremaining: 1.63s\n",
      "425:\tlearn: 503.3116968\ttotal: 4.32s\tremaining: 1.62s\n",
      "426:\tlearn: 503.1870225\ttotal: 4.33s\tremaining: 1.61s\n",
      "427:\tlearn: 502.9760975\ttotal: 4.34s\tremaining: 1.6s\n",
      "428:\tlearn: 502.7216641\ttotal: 4.35s\tremaining: 1.59s\n",
      "429:\tlearn: 502.6923021\ttotal: 4.36s\tremaining: 1.58s\n",
      "430:\tlearn: 502.6634711\ttotal: 4.37s\tremaining: 1.57s\n",
      "431:\tlearn: 502.4672647\ttotal: 4.38s\tremaining: 1.56s\n",
      "432:\tlearn: 502.4128495\ttotal: 4.39s\tremaining: 1.55s\n",
      "433:\tlearn: 502.3050244\ttotal: 4.4s\tremaining: 1.54s\n",
      "434:\tlearn: 502.2024629\ttotal: 4.41s\tremaining: 1.53s\n",
      "435:\tlearn: 502.0917915\ttotal: 4.42s\tremaining: 1.52s\n",
      "436:\tlearn: 502.0695994\ttotal: 4.43s\tremaining: 1.51s\n",
      "437:\tlearn: 502.0474351\ttotal: 4.44s\tremaining: 1.5s\n",
      "438:\tlearn: 501.9408713\ttotal: 4.45s\tremaining: 1.49s\n",
      "439:\tlearn: 501.9189949\ttotal: 4.46s\tremaining: 1.48s\n",
      "440:\tlearn: 501.8972863\ttotal: 4.47s\tremaining: 1.47s\n",
      "441:\tlearn: 501.8506653\ttotal: 4.48s\tremaining: 1.46s\n",
      "442:\tlearn: 501.7749526\ttotal: 4.49s\tremaining: 1.45s\n",
      "443:\tlearn: 501.7535642\ttotal: 4.5s\tremaining: 1.44s\n",
      "444:\tlearn: 501.5669555\ttotal: 4.51s\tremaining: 1.43s\n",
      "445:\tlearn: 501.5300013\ttotal: 4.53s\tremaining: 1.42s\n",
      "446:\tlearn: 501.4693609\ttotal: 4.54s\tremaining: 1.41s\n",
      "447:\tlearn: 501.3649226\ttotal: 4.54s\tremaining: 1.4s\n",
      "448:\tlearn: 501.2840204\ttotal: 4.55s\tremaining: 1.39s\n",
      "449:\tlearn: 501.1853025\ttotal: 4.57s\tremaining: 1.38s\n",
      "450:\tlearn: 501.0919116\ttotal: 4.58s\tremaining: 1.37s\n",
      "451:\tlearn: 500.9918985\ttotal: 4.59s\tremaining: 1.36s\n",
      "452:\tlearn: 500.9483815\ttotal: 4.6s\tremaining: 1.35s\n",
      "453:\tlearn: 500.7053375\ttotal: 4.61s\tremaining: 1.34s\n",
      "454:\tlearn: 500.4094591\ttotal: 4.62s\tremaining: 1.33s\n",
      "455:\tlearn: 500.2842719\ttotal: 4.63s\tremaining: 1.32s\n",
      "456:\tlearn: 500.2329358\ttotal: 4.64s\tremaining: 1.31s\n",
      "457:\tlearn: 500.1852283\ttotal: 4.65s\tremaining: 1.3s\n",
      "458:\tlearn: 499.9606814\ttotal: 4.66s\tremaining: 1.29s\n",
      "459:\tlearn: 499.9403324\ttotal: 4.67s\tremaining: 1.28s\n",
      "460:\tlearn: 499.8699737\ttotal: 4.68s\tremaining: 1.27s\n",
      "461:\tlearn: 499.6417693\ttotal: 4.7s\tremaining: 1.26s\n",
      "462:\tlearn: 499.6220907\ttotal: 4.71s\tremaining: 1.25s\n",
      "463:\tlearn: 499.5460275\ttotal: 4.72s\tremaining: 1.24s\n",
      "464:\tlearn: 499.5260856\ttotal: 4.73s\tremaining: 1.23s\n",
      "465:\tlearn: 499.4175953\ttotal: 4.74s\tremaining: 1.22s\n",
      "466:\tlearn: 499.3673529\ttotal: 4.75s\tremaining: 1.21s\n",
      "467:\tlearn: 499.2153077\ttotal: 4.76s\tremaining: 1.2s\n",
      "468:\tlearn: 499.1003271\ttotal: 4.77s\tremaining: 1.19s\n",
      "469:\tlearn: 499.0514711\ttotal: 4.78s\tremaining: 1.18s\n",
      "470:\tlearn: 499.0334054\ttotal: 4.79s\tremaining: 1.17s\n",
      "471:\tlearn: 498.9821493\ttotal: 4.8s\tremaining: 1.16s\n",
      "472:\tlearn: 498.9319557\ttotal: 4.81s\tremaining: 1.15s\n",
      "473:\tlearn: 498.8827789\ttotal: 4.82s\tremaining: 1.14s\n",
      "474:\tlearn: 498.8018533\ttotal: 4.83s\tremaining: 1.13s\n",
      "475:\tlearn: 498.7643080\ttotal: 4.84s\tremaining: 1.12s\n",
      "476:\tlearn: 498.6824932\ttotal: 4.85s\tremaining: 1.11s\n",
      "477:\tlearn: 498.5382467\ttotal: 4.86s\tremaining: 1.1s\n",
      "478:\tlearn: 498.3909918\ttotal: 4.87s\tremaining: 1.09s\n",
      "479:\tlearn: 498.2960613\ttotal: 4.88s\tremaining: 1.08s\n",
      "480:\tlearn: 498.1912453\ttotal: 4.89s\tremaining: 1.07s\n",
      "481:\tlearn: 498.1000948\ttotal: 4.9s\tremaining: 1.06s\n",
      "482:\tlearn: 498.0853279\ttotal: 4.91s\tremaining: 1.05s\n",
      "483:\tlearn: 498.0707271\ttotal: 4.92s\tremaining: 1.04s\n",
      "484:\tlearn: 497.9938664\ttotal: 4.93s\tremaining: 1.03s\n",
      "485:\tlearn: 497.9756617\ttotal: 4.94s\tremaining: 1.02s\n",
      "486:\tlearn: 497.8839435\ttotal: 4.95s\tremaining: 1.01s\n",
      "487:\tlearn: 497.8659380\ttotal: 4.96s\tremaining: 996ms\n",
      "488:\tlearn: 497.8480355\ttotal: 4.97s\tremaining: 986ms\n",
      "489:\tlearn: 497.7522471\ttotal: 4.98s\tremaining: 976ms\n",
      "490:\tlearn: 497.6734336\ttotal: 4.99s\tremaining: 966ms\n",
      "491:\tlearn: 497.6558156\ttotal: 5s\tremaining: 955ms\n",
      "492:\tlearn: 497.4316950\ttotal: 5.01s\tremaining: 945ms\n",
      "493:\tlearn: 497.3265496\ttotal: 5.02s\tremaining: 935ms\n",
      "494:\tlearn: 497.2127416\ttotal: 5.03s\tremaining: 925ms\n",
      "495:\tlearn: 497.0659859\ttotal: 5.04s\tremaining: 915ms\n",
      "496:\tlearn: 497.0306332\ttotal: 5.05s\tremaining: 905ms\n",
      "497:\tlearn: 497.0142940\ttotal: 5.06s\tremaining: 895ms\n",
      "498:\tlearn: 496.9600690\ttotal: 5.07s\tremaining: 885ms\n",
      "499:\tlearn: 496.8797857\ttotal: 5.08s\tremaining: 874ms\n",
      "500:\tlearn: 496.8037228\ttotal: 5.09s\tremaining: 864ms\n",
      "501:\tlearn: 496.7194429\ttotal: 5.1s\tremaining: 854ms\n",
      "502:\tlearn: 496.6044936\ttotal: 5.11s\tremaining: 844ms\n",
      "503:\tlearn: 496.5338071\ttotal: 5.12s\tremaining: 834ms\n",
      "504:\tlearn: 496.4510533\ttotal: 5.13s\tremaining: 824ms\n",
      "505:\tlearn: 496.4133767\ttotal: 5.14s\tremaining: 813ms\n",
      "506:\tlearn: 496.1547062\ttotal: 5.16s\tremaining: 803ms\n",
      "507:\tlearn: 496.0634678\ttotal: 5.17s\tremaining: 793ms\n",
      "508:\tlearn: 495.9274771\ttotal: 5.17s\tremaining: 783ms\n",
      "509:\tlearn: 495.7615666\ttotal: 5.19s\tremaining: 773ms\n",
      "510:\tlearn: 495.6202498\ttotal: 5.2s\tremaining: 763ms\n",
      "511:\tlearn: 495.4348955\ttotal: 5.21s\tremaining: 753ms\n",
      "512:\tlearn: 495.3078786\ttotal: 5.22s\tremaining: 743ms\n",
      "513:\tlearn: 495.1829545\ttotal: 5.23s\tremaining: 732ms\n",
      "514:\tlearn: 495.0752731\ttotal: 5.24s\tremaining: 722ms\n",
      "515:\tlearn: 494.9520778\ttotal: 5.25s\tremaining: 712ms\n",
      "516:\tlearn: 494.9236192\ttotal: 5.26s\tremaining: 702ms\n",
      "517:\tlearn: 494.8587091\ttotal: 5.27s\tremaining: 692ms\n",
      "518:\tlearn: 494.7072618\ttotal: 5.28s\tremaining: 682ms\n",
      "519:\tlearn: 494.5529522\ttotal: 5.29s\tremaining: 672ms\n",
      "520:\tlearn: 494.5359415\ttotal: 5.3s\tremaining: 661ms\n",
      "521:\tlearn: 494.4486648\ttotal: 5.31s\tremaining: 651ms\n",
      "522:\tlearn: 494.3439901\ttotal: 5.32s\tremaining: 641ms\n",
      "523:\tlearn: 494.2568641\ttotal: 5.33s\tremaining: 631ms\n",
      "524:\tlearn: 494.2400853\ttotal: 5.34s\tremaining: 621ms\n",
      "525:\tlearn: 494.1422046\ttotal: 5.35s\tremaining: 611ms\n",
      "526:\tlearn: 494.0753118\ttotal: 5.36s\tremaining: 600ms\n",
      "527:\tlearn: 494.0586960\ttotal: 5.37s\tremaining: 590ms\n",
      "528:\tlearn: 494.0396870\ttotal: 5.39s\tremaining: 581ms\n",
      "529:\tlearn: 493.8218823\ttotal: 5.41s\tremaining: 572ms\n",
      "530:\tlearn: 493.5960833\ttotal: 5.42s\tremaining: 562ms\n",
      "531:\tlearn: 493.4786914\ttotal: 5.44s\tremaining: 552ms\n",
      "532:\tlearn: 493.4196008\ttotal: 5.45s\tremaining: 542ms\n",
      "533:\tlearn: 493.1704154\ttotal: 5.46s\tremaining: 532ms\n",
      "534:\tlearn: 493.1128802\ttotal: 5.47s\tremaining: 522ms\n",
      "535:\tlearn: 493.0137619\ttotal: 5.48s\tremaining: 512ms\n",
      "536:\tlearn: 492.9755865\ttotal: 5.49s\tremaining: 501ms\n",
      "537:\tlearn: 492.8492585\ttotal: 5.5s\tremaining: 491ms\n",
      "538:\tlearn: 492.6767250\ttotal: 5.51s\tremaining: 481ms\n",
      "539:\tlearn: 492.5308112\ttotal: 5.53s\tremaining: 471ms\n",
      "540:\tlearn: 492.4315235\ttotal: 5.54s\tremaining: 460ms\n",
      "541:\tlearn: 492.2964564\ttotal: 5.54s\tremaining: 450ms\n",
      "542:\tlearn: 492.2578183\ttotal: 5.55s\tremaining: 440ms\n",
      "543:\tlearn: 492.2199199\ttotal: 5.57s\tremaining: 430ms\n",
      "544:\tlearn: 492.1392946\ttotal: 5.58s\tremaining: 419ms\n",
      "545:\tlearn: 492.0395303\ttotal: 5.58s\tremaining: 409ms\n",
      "546:\tlearn: 492.0236415\ttotal: 5.59s\tremaining: 399ms\n",
      "547:\tlearn: 491.9671518\ttotal: 5.61s\tremaining: 389ms\n",
      "548:\tlearn: 491.8595259\ttotal: 5.62s\tremaining: 378ms\n",
      "549:\tlearn: 491.8078805\ttotal: 5.63s\tremaining: 368ms\n",
      "550:\tlearn: 491.6311604\ttotal: 5.63s\tremaining: 358ms\n",
      "551:\tlearn: 491.5763089\ttotal: 5.64s\tremaining: 348ms\n",
      "552:\tlearn: 491.4739812\ttotal: 5.66s\tremaining: 337ms\n",
      "553:\tlearn: 491.2813667\ttotal: 5.66s\tremaining: 327ms\n",
      "554:\tlearn: 491.2333958\ttotal: 5.67s\tremaining: 317ms\n",
      "555:\tlearn: 491.1873811\ttotal: 5.68s\tremaining: 307ms\n",
      "556:\tlearn: 491.1396858\ttotal: 5.7s\tremaining: 297ms\n",
      "557:\tlearn: 491.0784236\ttotal: 5.71s\tremaining: 286ms\n",
      "558:\tlearn: 490.9364588\ttotal: 5.72s\tremaining: 276ms\n",
      "559:\tlearn: 490.7201268\ttotal: 5.73s\tremaining: 266ms\n",
      "560:\tlearn: 490.5636314\ttotal: 5.74s\tremaining: 256ms\n",
      "561:\tlearn: 490.4301668\ttotal: 5.75s\tremaining: 246ms\n",
      "562:\tlearn: 490.3161289\ttotal: 5.76s\tremaining: 235ms\n",
      "563:\tlearn: 490.2244422\ttotal: 5.77s\tremaining: 225ms\n",
      "564:\tlearn: 490.1730166\ttotal: 5.78s\tremaining: 215ms\n",
      "565:\tlearn: 490.1280446\ttotal: 5.79s\tremaining: 205ms\n",
      "566:\tlearn: 490.0124537\ttotal: 5.8s\tremaining: 194ms\n",
      "567:\tlearn: 489.8727768\ttotal: 5.81s\tremaining: 184ms\n",
      "568:\tlearn: 489.7781491\ttotal: 5.82s\tremaining: 174ms\n",
      "569:\tlearn: 489.5512724\ttotal: 5.83s\tremaining: 164ms\n",
      "570:\tlearn: 489.4265912\ttotal: 5.84s\tremaining: 153ms\n",
      "571:\tlearn: 489.3685364\ttotal: 5.85s\tremaining: 143ms\n",
      "572:\tlearn: 489.1817714\ttotal: 5.86s\tremaining: 133ms\n",
      "573:\tlearn: 489.0838134\ttotal: 5.87s\tremaining: 123ms\n",
      "574:\tlearn: 488.9169291\ttotal: 5.88s\tremaining: 112ms\n",
      "575:\tlearn: 488.8439144\ttotal: 5.89s\tremaining: 102ms\n",
      "576:\tlearn: 488.6244326\ttotal: 5.9s\tremaining: 92ms\n",
      "577:\tlearn: 488.5118297\ttotal: 5.91s\tremaining: 81.8ms\n",
      "578:\tlearn: 488.3992767\ttotal: 5.92s\tremaining: 71.6ms\n",
      "579:\tlearn: 488.3767139\ttotal: 5.93s\tremaining: 61.3ms\n",
      "580:\tlearn: 488.1890660\ttotal: 5.94s\tremaining: 51.1ms\n",
      "581:\tlearn: 488.1463858\ttotal: 5.95s\tremaining: 40.9ms\n",
      "582:\tlearn: 488.0987931\ttotal: 5.96s\tremaining: 30.7ms\n",
      "583:\tlearn: 487.9289645\ttotal: 5.97s\tremaining: 20.4ms\n",
      "584:\tlearn: 487.7628530\ttotal: 5.98s\tremaining: 10.2ms\n",
      "585:\tlearn: 487.6031125\ttotal: 5.99s\tremaining: 0us\n",
      "cat RMSE: 538.9357725249145\n"
     ]
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "cat_model = CatBoostRegressor(**best_params)\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "# RMSE 계산\n",
    "rmse_cat = mean_squared_error(y_test, y_pred_cat, squared=False)\n",
    "print(f\"cat RMSE: {rmse_cat}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:32:38.981474900Z",
     "start_time": "2024-04-03T15:32:32.749233100Z"
    }
   },
   "id": "8f17a743e7a797be"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "final_pred = (y_pred_xgb + y_pred_lgbm+y_pred_cat )/3\n",
    "\n",
    "final_pred[final_pred<100] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:33:12.792148900Z",
     "start_time": "2024-04-03T15:33:12.768213100Z"
    }
   },
   "id": "bf6cd9110915abf6"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "array([910.9977906 , 611.97180012,   0.        , ..., 853.09560826,\n         0.        , 886.60217871])"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:33:14.350247500Z",
     "start_time": "2024-04-03T15:33:14.329304Z"
    }
   },
   "id": "c63447b866be909e"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "536.5749985501996"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_xgb = mean_squared_error(y_test, final_pred, squared=False)\n",
    "rmse_xgb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:33:22.636630800Z",
     "start_time": "2024-04-03T15:33:22.611697400Z"
    }
   },
   "id": "afc4f04bc793b8cf"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "pred_final_xgb = xgb_model.predict(test)\n",
    "# pred_final_xgb = np.expm1(pred_final_xgb)\n",
    "# pred_final_xgb[pred_final_xgb<100] = 0\n",
    "\n",
    "pred_final_cat = cat_model.predict(test)\n",
    "# pred_final = np.expm1(pred_final)\n",
    "# pred_final_cat[pred_final_cat<100] = 0\n",
    "\n",
    "pred_final_lgbm = lgbm_model.predict(test)\n",
    "# pred_final = np.expm1(pred_final)\n",
    "# pred_final_lgbm[pred_final_lgbm<100] = 0\n",
    "# \n",
    "# pred_final_dt = dt_model.predict(test)\n",
    "# # pred_final = np.expm1(pred_final)\n",
    "# pred_final_dt[pred_final_dt<100] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:33:55.367081200Z",
     "start_time": "2024-04-03T15:33:55.217431300Z"
    }
   },
   "id": "acda7f5dd8135687"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# pred_final_xgb, pred_final_cat, pred_final_lgbm은 NumPy 배열로 가정\n",
    "# 이 배열들은 각 모델의 예측값을 담고 있음\n",
    "\n",
    "# 세 모델의 예측값을 평균내어 최종 예측값 계산\n",
    "pred_ensemble = (pred_final_xgb +  pred_final_lgbm+ pred_final_cat) / 3\n",
    "pred_ensemble[pred_ensemble<100] = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:34:12.003173700Z",
     "start_time": "2024-04-03T15:34:11.977214300Z"
    }
   },
   "id": "81e9398f5000335c"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "             ID      Income\n0     TEST_0000    0.000000\n1     TEST_0001    0.000000\n2     TEST_0002  443.869962\n3     TEST_0003  587.714966\n4     TEST_0004    0.000000\n...         ...         ...\n9995  TEST_9995  933.756089\n9996  TEST_9996  654.530351\n9997  TEST_9997  469.184484\n9998  TEST_9998    0.000000\n9999  TEST_9999  641.008980\n\n[10000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Income</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_0000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_0001</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_0002</td>\n      <td>443.869962</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_0003</td>\n      <td>587.714966</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_0004</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>TEST_9995</td>\n      <td>933.756089</td>\n    </tr>\n    <tr>\n      <th>9996</th>\n      <td>TEST_9996</td>\n      <td>654.530351</td>\n    </tr>\n    <tr>\n      <th>9997</th>\n      <td>TEST_9997</td>\n      <td>469.184484</td>\n    </tr>\n    <tr>\n      <th>9998</th>\n      <td>TEST_9998</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9999</th>\n      <td>TEST_9999</td>\n      <td>641.008980</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "pred_final_cat[pred_final_cat<100] = 0\n",
    "submission['Income'] = pred_final_cat\n",
    "submission"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:48:32.449233200Z",
     "start_time": "2024-04-03T15:48:32.424299700Z"
    }
   },
   "id": "6bd6d83021a2cdf"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "submission.to_csv(\"../submission/test27.csv\", index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:48:37.555615300Z",
     "start_time": "2024-04-03T15:48:37.515719900Z"
    }
   },
   "id": "a99e9c831debac82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b47c2982003a4169"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
