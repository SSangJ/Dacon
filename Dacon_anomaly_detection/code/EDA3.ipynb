{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:37:11.752539100Z",
     "start_time": "2024-02-20T03:37:08.643106800Z"
    }
   },
   "id": "e8899d492dada60f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-20T03:37:20.755865Z",
     "start_time": "2024-02-20T03:37:17.876988800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 데이터 로딩 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): csv 파일의 경로.\n",
    "            transform (callable, optional): 샘플에 적용될 Optional transform.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df['img_path'].iloc[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        target = torch.tensor([0.]).float()\n",
    "        return image, target\n",
    "\n",
    "# 이미지 전처리 및 임베딩\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_data = CustomDataset(csv_file='../data/train.csv', transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=False)\n",
    "\n",
    "test_data = CustomDataset(csv_file='../data/test.csv', transform=transform)\n",
    "test_loader = DataLoader(test_data, batch_size=16 ,shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T04:08:07.923381800Z",
     "start_time": "2024-02-20T04:08:07.904432700Z"
    }
   },
   "id": "2da6f77c3ba29f87"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "\n",
    "        # 인코더 정의\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 32 * 32, 1024),  # 32*32는 입력 이미지 크기에 따라 조정해야 할 수 있음\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # 디코더 정의\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(1024, 512 * 32 * 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (512, 32, 32)),  # Unflatten 레이어로 차원 복원\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T04:44:53.933449Z",
     "start_time": "2024-02-20T04:44:53.916493700Z"
    }
   },
   "id": "d51893e71f578675"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# 모델, 손실 함수 및 최적화 알고리즘 설정\n",
    "autoencoder = CNNAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.01)\n",
    "# 스케줄러 설정\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.9)  # 10 에폭마다 학습률을 0.1배로 감소"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T04:45:01.234381400Z",
     "start_time": "2024-02-20T04:44:54.202293800Z"
    }
   },
   "id": "7b9bb7f416d655b9"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# 학습 루프 정의\n",
    "def train_model(dataloader, model, criterion, optimizer, scheduler, epochs=30):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        scheduler.step()  # 에폭마다 스케줄러를 업데이트\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, LR: {scheduler.get_last_lr()[0]}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T04:45:03.238131800Z",
     "start_time": "2024-02-20T04:45:03.223171900Z"
    }
   },
   "id": "c1f99d27428cb5c9"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7288, LR: 0.009000000000000001\n",
      "Epoch 2/50, Loss: 0.2396, LR: 0.008100000000000001\n",
      "Epoch 3/50, Loss: 0.1937, LR: 0.007290000000000001\n",
      "Epoch 4/50, Loss: 0.1818, LR: 0.006561000000000002\n",
      "Epoch 5/50, Loss: 0.1749, LR: 0.005904900000000002\n",
      "Epoch 6/50, Loss: 0.1679, LR: 0.005314410000000002\n",
      "Epoch 7/50, Loss: 0.1610, LR: 0.004782969000000002\n",
      "Epoch 8/50, Loss: 0.1551, LR: 0.004304672100000002\n",
      "Epoch 9/50, Loss: 0.1495, LR: 0.003874204890000002\n",
      "Epoch 10/50, Loss: 0.1443, LR: 0.003486784401000002\n",
      "Epoch 11/50, Loss: 0.1399, LR: 0.003138105960900002\n",
      "Epoch 12/50, Loss: 0.1352, LR: 0.0028242953648100018\n",
      "Epoch 13/50, Loss: 0.1300, LR: 0.0025418658283290017\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[45], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 학습 루프 실행\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mautoencoder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[44], line 16\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(dataloader, model, criterion, optimizer, scheduler, epochs)\u001B[0m\n\u001B[0;32m     13\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     14\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 16\u001B[0m     running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m inputs\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     18\u001B[0m scheduler\u001B[38;5;241m.\u001B[39mstep()  \u001B[38;5;66;03m# 에폭마다 스케줄러를 업데이트\u001B[39;00m\n\u001B[0;32m     20\u001B[0m epoch_loss \u001B[38;5;241m=\u001B[39m running_loss \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(dataloader\u001B[38;5;241m.\u001B[39mdataset)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 루프 실행\n",
    "train_model(train_loader, autoencoder, criterion, optimizer, scheduler, epochs=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T05:06:29.455366Z",
     "start_time": "2024-02-20T04:45:03.626355800Z"
    }
   },
   "id": "5a4612227c2a9fd1"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0: Anomaly\n",
      "Image 1: Normal\n",
      "Image 2: Normal\n",
      "Image 3: Anomaly\n",
      "Image 4: Normal\n",
      "Image 5: Normal\n",
      "Image 6: Anomaly\n",
      "Image 7: Normal\n",
      "Image 8: Normal\n",
      "Image 9: Anomaly\n",
      "Image 10: Normal\n",
      "Image 11: Anomaly\n",
      "Image 12: Normal\n",
      "Image 13: Normal\n",
      "Image 14: Normal\n",
      "Image 15: Anomaly\n",
      "Image 16: Anomaly\n",
      "Image 17: Anomaly\n",
      "Image 18: Anomaly\n",
      "Image 19: Normal\n",
      "Image 20: Normal\n",
      "Image 21: Normal\n",
      "Image 22: Anomaly\n",
      "Image 23: Normal\n",
      "Image 24: Normal\n",
      "Image 25: Normal\n",
      "Image 26: Anomaly\n",
      "Image 27: Anomaly\n",
      "Image 28: Anomaly\n",
      "Image 29: Anomaly\n",
      "Image 30: Anomaly\n",
      "Image 31: Normal\n",
      "Image 32: Normal\n",
      "Image 33: Anomaly\n",
      "Image 34: Anomaly\n",
      "Image 35: Anomaly\n",
      "Image 36: Anomaly\n",
      "Image 37: Normal\n",
      "Image 38: Anomaly\n",
      "Image 39: Anomaly\n",
      "Image 40: Normal\n",
      "Image 41: Anomaly\n",
      "Image 42: Normal\n",
      "Image 43: Anomaly\n",
      "Image 44: Normal\n",
      "Image 45: Anomaly\n",
      "Image 46: Normal\n",
      "Image 47: Normal\n",
      "Image 48: Normal\n",
      "Image 49: Anomaly\n",
      "Image 50: Normal\n",
      "Image 51: Anomaly\n",
      "Image 52: Normal\n",
      "Image 53: Anomaly\n",
      "Image 54: Normal\n",
      "Image 55: Anomaly\n",
      "Image 56: Normal\n",
      "Image 57: Normal\n",
      "Image 58: Anomaly\n",
      "Image 59: Anomaly\n",
      "Image 60: Anomaly\n",
      "Image 61: Anomaly\n",
      "Image 62: Anomaly\n",
      "Image 63: Anomaly\n",
      "Image 64: Anomaly\n",
      "Image 65: Anomaly\n",
      "Image 66: Anomaly\n",
      "Image 67: Anomaly\n",
      "Image 68: Normal\n",
      "Image 69: Anomaly\n",
      "Image 70: Normal\n",
      "Image 71: Normal\n",
      "Image 72: Normal\n",
      "Image 73: Anomaly\n",
      "Image 74: Anomaly\n",
      "Image 75: Normal\n",
      "Image 76: Normal\n",
      "Image 77: Anomaly\n",
      "Image 78: Normal\n",
      "Image 79: Anomaly\n",
      "Image 80: Normal\n",
      "Image 81: Anomaly\n",
      "Image 82: Normal\n",
      "Image 83: Normal\n",
      "Image 84: Normal\n",
      "Image 85: Normal\n",
      "Image 86: Anomaly\n",
      "Image 87: Anomaly\n",
      "Image 88: Anomaly\n",
      "Image 89: Anomaly\n",
      "Image 90: Anomaly\n",
      "Image 91: Anomaly\n",
      "Image 92: Anomaly\n",
      "Image 93: Anomaly\n",
      "Image 94: Anomaly\n",
      "Image 95: Normal\n",
      "Image 96: Anomaly\n",
      "Image 97: Anomaly\n",
      "Image 98: Anomaly\n",
      "Image 99: Normal\n"
     ]
    }
   ],
   "source": [
    "def anomaly_detection(test_loader, model, threshold):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    anomalies = []  # 이상 탐지 결과를 저장할 리스트\n",
    "\n",
    "    with torch.no_grad():  # 그래디언트 계산을 비활성화\n",
    "        for data in test_loader:\n",
    "            images, _ = data\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = nn.functional.mse_loss(outputs, images, reduction='none')\n",
    "            loss = loss.view(loss.size(0), -1).mean(1)  # 각 이미지에 대한 평균 MSE 손실 계산\n",
    "            anomalies.extend(loss > threshold)  # 임계값을 기준으로 이상 여부 판단\n",
    "\n",
    "    anomalies = torch.stack(anomalies)\n",
    "    return anomalies\n",
    "\n",
    "# 임계값 설정 (실제 값은 데이터에 따라 조정 필요)\n",
    "threshold = 0.1400\n",
    "\n",
    "# 이상 탐지 실행\n",
    "anomalies = anomaly_detection(test_loader, autoencoder, threshold)\n",
    "\n",
    "# 이상 탐지 결과 출력\n",
    "for i, is_anomaly in enumerate(anomalies):\n",
    "    print(f'Image {i}: {\"Anomaly\" if is_anomaly else \"Normal\"}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T05:06:56.491448Z",
     "start_time": "2024-02-20T05:06:50.324992400Z"
    }
   },
   "id": "a3de894353d858f1"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "anomalies = anomalies.int().cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T05:10:55.163679200Z",
     "start_time": "2024-02-20T05:10:55.145727500Z"
    }
   },
   "id": "d89f52ca3409d6a9"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../submission/sample_submission.csv\")\n",
    "submission['label'] = anomalies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T05:10:55.787492700Z",
     "start_time": "2024-02-20T05:10:55.770537600Z"
    }
   },
   "id": "8f8fd63618a2baa"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "          id  label\n0   TEST_000      1\n1   TEST_001      0\n2   TEST_002      0\n3   TEST_003      1\n4   TEST_004      0\n..       ...    ...\n95  TEST_095      0\n96  TEST_096      1\n97  TEST_097      1\n98  TEST_098      1\n99  TEST_099      0\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_001</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_002</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_003</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_004</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>TEST_095</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>TEST_096</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>TEST_097</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>TEST_098</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>TEST_099</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T05:10:57.197194Z",
     "start_time": "2024-02-20T05:10:57.164115800Z"
    }
   },
   "id": "e8acc305264f1256"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "submission.to_csv(\"../submission/submission_5.csv\",index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T05:11:04.828691800Z",
     "start_time": "2024-02-20T05:11:04.804756200Z"
    }
   },
   "id": "559dc0872a806984"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "submit.to_csv(\"../submission/submission_4.csv\",index = False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-19T05:39:45.515633300Z",
     "start_time": "2024-02-19T05:39:45.501671300Z"
    }
   },
   "id": "b4479a66f58e7bcd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f4bb152f517d8c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "study",
   "language": "python",
   "display_name": "study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
